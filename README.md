# Transformer-Based UE Localization

![Tests](https://img.shields.io/badge/tests-52%20passed-brightgreen)
![Python](https://img.shields.io/badge/python-3.12-blue)
![License](https://img.shields.io/badge/license-MIT-blue)

**Transformer-based deep learning system for 5G NR UE localization using multi-layer radio measurements.**

## Overview

This project implements an end-to-end pipeline for training transformer models to localize 5G NR User Equipment (UE) using:
- **Layer 1 (RT)**: Ray tracing propagation features (path gains, AoA/AoD, delays)
- **Layer 2 (PHY/FAPI)**: Link-level measurements (RSRP, RSRQ, CQI, RI)
- **Layer 3 (MAC/RRC)**: System-level features (cell IDs, timing advance, throughput)

### Key Features

‚úÖ **3GPP Compliant**: All measurements follow official 3GPP specifications (38.215, 38.214, 38.213)  
‚úÖ **Multi-Layer Architecture**: RT ‚Üí PHY/FAPI ‚Üí MAC/RRC feature extraction  
‚úÖ **Synthetic Data Generation**: Sionna RT + OpenStreetMap for realistic scenarios  
‚úÖ **Map Conditioning**: Dual-encoder with radio + geometry maps  
‚úÖ **Production Ready**: 52 passing tests, comprehensive documentation  

---

## Project Status

| Milestone | Status | Tests | Implementation |
|-----------|--------|-------|----------------|
| M1: Scene Generation | ‚úÖ COMPLETE | 25/26 passing | 1,461 lines |
| M2: Data Generation | ‚úÖ COMPLETE | 27/27 passing | 2,149 lines |
| M3: Transformer Model | üîÑ NEXT | - | Planned |
| M4: Training Pipeline | ‚è≠Ô∏è PENDING | - | Planned |
| M5: Web UI | ‚è≠Ô∏è PENDING | - | Planned |

---

## Quick Start

### Installation

```bash
# Clone repository
git clone <repository-url>
cd transformer-ue-localization

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements-test.txt  # M1 dependencies
pip install -r requirements-m2.txt    # M2 dependencies
```

### Run Tests

```bash
# All tests
pytest tests/ -v

# M1 only (Scene Generation)
pytest tests/test_m1_scene_generation.py -v

# M2 only (Data Generation)
pytest tests/test_m2_data_generation.py -v
```

**Expected:** 52 passed, 1 skipped

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              M1: Scene Generation                          ‚îÇ
‚îÇ  OpenStreetMap ‚Üí Geo2SigMap ‚Üí Mitsuba XML + Meshes       ‚îÇ
‚îÇ  + Material Randomization (ITU-R P.2040)                  ‚îÇ
‚îÇ  + Site Placement (grid/random/ISD/custom)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ scene.xml, meshes, metadata.json
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              M2: Data Generation                           ‚îÇ
‚îÇ  Sionna RT ‚Üí Path Features ‚Üí PHY/FAPI ‚Üí MAC/RRC          ‚îÇ
‚îÇ  + 3GPP Measurements (RSRP, CQI, TA, etc.)                ‚îÇ
‚îÇ  + Measurement Realism (dropout, quantization)            ‚îÇ
‚îÇ  + Zarr Storage (hierarchical, compressed)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ dataset.zarr (rt/phy/mac features)
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          M3: Transformer Model (NEXT)                      ‚îÇ
‚îÇ  Dual Encoder (Radio + Map) ‚Üí Cross-Attention ‚Üí Position ‚îÇ
‚îÇ  + PyTorch Dataset from Zarr                              ‚îÇ
‚îÇ  + Temporal + Spatial + Protocol Positional Encoding      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Usage Examples

### M1: Generate Synthetic Scenes

```bash
python scripts/generate_scenes.py \
  --area "Boulder, CO" \
  --num-sites 10 \
  --site-strategy isd \
  --randomize-materials \
  --output-dir data/scenes/
```

### M2: Generate Training Dataset

```bash
python scripts/generate_dataset.py \
  --scene-dir data/scenes/ \
  --output-dir data/synthetic/ \
  --num-ue 100 \
  --num-reports 10 \
  --carrier-freq 3.5e9 \
  --enable-beam-mgmt
```

### M3: Train Transformer (Coming Soon)

```bash
python scripts/train.py \
  --dataset data/synthetic/dataset_*.zarr \
  --model-config configs/model.yaml \
  --batch-size 32 \
  --epochs 100
```

---

## Project Structure

```
transformer-ue-localization/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scene_generation/      # M1: Scene generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core.py             # SceneGenerator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ materials.py        # MaterialRandomizer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sites.py            # SitePlacer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tiles.py            # TileGenerator
‚îÇ   ‚îî‚îÄ‚îÄ data_generation/        # M2: Data generation
‚îÇ       ‚îú‚îÄ‚îÄ measurement_utils.py # 3GPP measurements
‚îÇ       ‚îú‚îÄ‚îÄ features.py          # RT/PHY/MAC extractors
‚îÇ       ‚îú‚îÄ‚îÄ multi_layer_generator.py # Pipeline orchestrator
‚îÇ       ‚îî‚îÄ‚îÄ zarr_writer.py       # Dataset storage
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_scenes.py      # M1 CLI
‚îÇ   ‚îî‚îÄ‚îÄ generate_dataset.py     # M2 CLI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_m1_scene_generation.py  # 26 tests
‚îÇ   ‚îî‚îÄ‚îÄ test_m2_data_generation.py   # 27 tests
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ scene_generation.yaml   # M1 config
‚îÇ   ‚îî‚îÄ‚îÄ data_generation.yaml    # M2 config
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ M1_COMPLETE.md          # M1 documentation
    ‚îú‚îÄ‚îÄ M2_COMPLETE.md          # M2 documentation
    ‚îî‚îÄ‚îÄ PROJECT_STATUS.md       # Overall status
```

---

## Key Technologies

- **Geo2SigMap v2.0.0**: OSM ‚Üí Sionna scene pipeline
- **Sionna RT v0.14+**: NVIDIA ray tracing framework
- **Zarr v3**: Hierarchical array storage
- **PyTorch 2.0+**: Deep learning framework
- **3GPP Standards**: 38.215, 38.214, 38.213, 38.331

---

## Documentation

- [M1 Complete Guide](docs/M1_COMPLETE.md) - Scene generation deep dive
- [M2 Complete Guide](M2_COMPLETE.md) - Data generation deep dive
- [Project Status](PROJECT_STATUS.md) - Overall progress and roadmap
- [Implementation Guide](IMPLEMENTATION_GUIDE.md) - Full architecture

---

## Testing

### Test Coverage

- **M1 (Scene Generation)**: 26 tests
  - MaterialRandomizer: 9 tests
  - SitePlacer: 8 tests
  - TileGenerator: 5 tests
  - Integration: 4 tests

- **M2 (Data Generation)**: 27 tests
  - MeasurementUtils: 8 tests
  - RTFeatureExtractor: 5 tests
  - PHYFAPIFeatureExtractor: 3 tests
  - MACRRCFeatureExtractor: 4 tests
  - MultiLayerDataGenerator: 5 tests
  - ZarrWriter: 2 tests

**Total: 52 passing, 1 skipped**

### Run Specific Tests

```bash
# Test material randomization
pytest tests/test_m1_scene_generation.py::TestMaterialRandomizer -v

# Test 3GPP measurements
pytest tests/test_m2_data_generation.py::TestMeasurementUtils -v

# Test Zarr storage
pytest tests/test_m2_data_generation.py::TestZarrWriter -v
```

---

## Performance

### M1 Scene Generation
- **Throughput**: 1-5 scenes/minute
- **Scene size**: 50-200 MB (XML + meshes)
- **Scaling**: Linear with geographic area

### M2 Data Generation
- **Mock mode**: ~100 UEs/second (CPU)
- **Full Sionna RT**: ~10 UEs/second (GPU)
- **Dataset size**: ~8 GB (compressed) for 1M samples

---

## Dependencies

### Core Requirements
```
numpy>=1.24.0
pyproj>=3.6.0
pyyaml>=6.0
zarr>=2.16.0
pytest>=7.4.0
```

### Optional (for production)
```
sionna>=0.14.0       # Ray tracing (requires TensorFlow)
tensorflow>=2.13.0   # Sionna dependency
torch>=2.0.0         # M3 training
```

---

## Contributing

This is a research project. Contributions welcome for:
- M3: Transformer model architecture
- M4: Training pipeline and evaluation
- M5: Web-based visualization UI
- Performance optimizations
- Additional test coverage

---

## License

MIT License - See LICENSE file for details

---

## Citation

If you use this code in your research, please cite:

```bibtex
@software{transformer_ue_localization,
  title={Transformer-Based UE Localization with Multi-Layer Radio Measurements},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/transformer-ue-localization}
}
```

---

## Acknowledgments

- **Geo2SigMap**: OSM to Sionna scene conversion
- **Sionna RT**: NVIDIA ray tracing framework
- **3GPP**: Wireless specifications
- **Zarr**: Array storage format

---

**Status: M1 + M2 Complete | M3 In Progress**
