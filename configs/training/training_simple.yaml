# Simplified Training Configuration for End-to-End Test

model:
  name: "MapConditionedTransformer"
  
  radio_encoder:
    num_cells: 8  # Maximum number of cells to track
    num_beams: 64  # Number of SSB beams
    d_model: 256
    nhead: 8
    num_layers: 4
    dropout: 0.1
    max_seq_len: 100  # Max measurement reports
    rt_features_dim: 10  # RSRP, RSRQ, PathGain, ToA, AoA, etc.
    phy_features_dim: 8  # L1-RSRP, SINR, RI, CQI, etc.
    mac_features_dim: 6  # TAC, handover count, etc.
    
  map_encoder:
    img_size: 256  # 256x256 pixel map
    patch_size: 16  # 16x16 patches
    in_channels: 10  # Combined radio + OSM map features
    d_model: 256
    nhead: 8
    num_layers: 4
    dropout: 0.1
    radio_map_channels: 5  # PathGain, ToA, SNR, SINR, Throughput
    osm_map_channels: 5  # height, footprint, material, road, terrain
    
  fusion:
    d_fusion: 256
    nhead: 8
    dropout: 0.1
    
  coarse_head:
    grid_size: 32  # 32x32 grid
    dropout: 0.1
    
  fine_head:
    type: "heteroscedastic"
    top_k: 5
    d_hidden: 128
    dropout: 0.1

dataset:
  zarr_path: "data/processed/quick_test_dataset/dataset_20251224_131441.zarr"
  scene_extent: 856  # Scene size in meters
  map_resolution: 1.0  # Meters per pixel
  normalize_features: true
  handle_missing_values: "mask"

training:
  batch_size: 16  # Small batch for CPU
  num_workers: 2
  pin_memory: false
    
  optimizer: "adamw"
  learning_rate: 0.0001
  weight_decay: 0.01
    
  scheduler: "constant"
  warmup_steps: 10
    
  num_epochs: 1  # Short test run
  gradient_clip: 1.0
  gradient_clip_val: 1.0
    
  loss:
    coarse_weight: 1.0
    fine_weight: 1.0
    
  callbacks:
    model_checkpoint:
      monitor: "val_median_error"
      save_top_k: 1
      mode: "min"
      
  validation:
    check_val_every_n_epoch: 1
    
  logging:
    log_every_n_steps: 10

infrastructure:
  accelerator: "gpu"
  devices: 1
  precision: "32"
  num_workers: 2
  checkpoint:
    monitor: "train_loss_epoch"
    mode: "min"
    save_top_k: 1
  early_stopping:
    monitor: "train_loss_epoch"
    patience: 10
    mode: "min"
  logging:
    use_wandb: false
    project: "transformer-ue-localization"
    log_every_n_steps: 10
