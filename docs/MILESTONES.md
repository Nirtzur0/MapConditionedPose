# Project Milestones üéØ

A compact status tracker for all major implementation milestones.

---

## Overview

| Milestone | Status | Tests | Lines |
|-----------|--------|-------|-------|
| **M1**: Scene Generation | ‚úÖ Complete | 18/18 | ~1,500 |
| **M2**: Data Generation | ‚úÖ Complete | 30/30 | ~2,100 |
| **M3**: Transformer Model | ‚úÖ Complete | 19/19 | ~2,000 |
| **M4**: Physics Loss | ‚úÖ Complete | 17/17 | ~1,000 |
| **M5**: Web Interface | ‚úÖ Complete | Manual | ~500 |

**Total**: ~7,000 lines of production code + 1,500 lines of tests.

---

## M1: Scene Generation ‚úÖ

**Purpose**: Generate synthetic 5G NR scenes from OpenStreetMap data.

**Key Components**:
- `SceneGenerator`: Deep Scene Builder integration via importlib
- `MaterialRandomizer`: ITU-R P.2040 materials (Œµ_r, œÉ randomization)
- `SitePlacer`: Grid, random, ISD, custom placement strategies
- `TileGenerator`: WGS84 ‚Üî UTM coordinate transforms

**Output**: `data/scenes/{scene_id}/scene.xml` + meshes + `metadata.json`

**What We Add to Scene Builder**:
- Material domain randomization for diverse training
- Multi-strategy site placement with 3GPP antenna patterns
- Comprehensive metadata for downstream M2 pipeline

---

## M2: Data Generation ‚úÖ

**Purpose**: Extract RT, PHY/FAPI, and MAC/RRC features from Sionna simulations.

**Key Components**:
- `measurement_utils.py`: 3GPP-compliant RSRP, RSRQ, SINR, CQI, TA
- `features.py`: RT, PHY/FAPI, MAC/RRC feature extractors
- `multi_layer_generator.py`: End-to-end pipeline orchestrator
- `zarr_writer.py`: Hierarchical array storage with Blosc compression

**Output**: `data/processed/dataset_*.zarr/` with rt_layer/, phy_fapi_layer/, mac_rrc_layer/

**Measurement Realism**:
- Quantization: 1 dB (RSRP), 0.5 dB (RSRQ), discrete CQI
- Dropout: 5% (RSRP) to 30% (neighbors)
- Temporal: 5-20 reports/UE @ 200ms intervals

---

## M3: Transformer Model ‚úÖ

**Purpose**: Dual-encoder transformer for UE localization with map conditioning.

**Architecture**:
```
RadioEncoder (temporal measurements)
      ‚Üì
CrossAttentionFusion ‚Üê MapEncoder (OSM + radio maps)
      ‚Üì
CoarseHead ‚Üí FineHead ‚Üí Position (x, y)
```

**Key Features**:
- Radio encoder: Multi-head self-attention across time steps
- Map encoder: Vision transformer with patch embedding
- Fusion: Cross-attention between radio and spatial features
- Output: Coarse grid classification + fine offset regression

---

## M4: Physics Loss ‚úÖ

**Purpose**: Differentiable physics regularization using precomputed radio maps.

**Loss Formulation**:
$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{coarse}} + \lambda_{\text{fine}} \mathcal{L}_{\text{fine}} + \lambda_{\text{phys}} \mathcal{L}_{\text{phys}}$$

Where:
$$\mathcal{L}_{\text{phys}} = \sum_{f} w_f \left\| m_f^{\text{obs}} - \text{RadioMap}_f(\hat{x}) \right\|^2$$

**Key Components**:
- `DifferentiableLookup`: Bilinear interpolation via `F.grid_sample`
- `PhysicsLoss`: Multi-feature weighted MSE
- `RadioMapGenerator`: 7-channel Sionna maps (path_gain, ToA, AoA, SNR, SINR, throughput, BLER)
- `PositionRefinement`: Gradient-based inference-time optimization

**When It Helps Most**: NLOS scenarios, sparse measurements, urban canyons.

---

## M5: Web Interface ‚úÖ

**Purpose**: Training monitoring and prediction visualization.

**Components**:
- Streamlit app (`web/app.py`): Interactive map explorer
- Error analysis: CDF plots, percentile metrics
- Prediction overlay: GT vs predicted positions

**Run It**:
```bash
streamlit run web/app.py
# Open http://localhost:8501
```

---

## Running Tests

```bash
# All tests
pytest tests/ -v

# By milestone
pytest tests/test_m1_scene_generation.py -v
pytest tests/test_m2_data_generation.py -v
pytest tests/test_m3_model.py -v
pytest tests/test_m4_physics_loss.py -v
```
