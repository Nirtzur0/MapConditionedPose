
\documentclass[11pt,a4paper]{article}

% ---------------------------------------------
% Packages
% ---------------------------------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{geometry}
\geometry{margin=1in}

\usepackage{amsmath,amssymb,amsfonts,amsthm,mathtools}
\usepackage{bm}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{xcolor}
\usepackage{soul} % Added for highligting
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

\usepackage{fancyhdr}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows.meta,shapes.geometric,fit,calc,backgrounds,decorations.pathreplacing}

% ---------------------------------------------
% Header / Footer
% ---------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\lhead{Research Draft}
\rhead{Physics-Informed Map-Conditioned UE Localization}
\cfoot{\thepage}
\setlength{\headheight}{14pt}

% ---------------------------------------------
% Macros
% ---------------------------------------------
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\tr}{\mathrm{tr}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\LogSumExp}{LogSumExp}

% Semantic highlighting commands
% Pink: Problems, Challenges, Constraints
\DeclareRobustCommand{\hlprob}[1]{{\sethlcolor{pink}\hl{#1}}}
% Yellow: Solutions, Key Innovations, Core Concepts
\DeclareRobustCommand{\hlsol}[1]{{\sethlcolor{yellow}\hl{#1}}}

% Theorem environments (kept lightweight; we use them for invariance statements)
\newtheorem{proposition}{Proposition}

% ---------------------------------------------
\title{\vspace{-0.8cm}\textbf{Physics-Informed Map-Conditioned Transformers for Probabilistic UE Localization}\\
\vspace{0.1cm}\large Coarse-to-Fine Re-ranked Hypotheses, Differentiable Radio-Map Likelihoods, and Test-Time Refinement}
\author{Nir Tzur}
\date{\vspace{-0.2cm}\today}

\begin{document}
\maketitle
\vspace{-0.6cm}

\begin{abstract}
Localizing user equipment (UE) from sparse, irregular radio measurements is an \hlprob{ill-posed inverse problem}: multiple spatial hypotheses can explain the same measurements, and \hlprob{purely data-driven predictors can violate basic propagation constraints}. We present a \hlsol{map-conditioned Transformer} that amortizes Bayesian inference over UE position while remaining tightly coupled to a physics simulator through a \hlsol{differentiable radio-map likelihood}.
The model (i) encodes measurement sequences as sets of timestamped, multi-layer features, (ii) encodes multi-channel environmental context (radio maps and semantic GIS layers) via a vision Transformer, (iii) fuses both modalities with cross-attention, and (iv) outputs a \hlsol{coarse-to-fine} \hlsol{top-$K$ re-ranked hypothesis distribution} over 2D position.
Training combines coarse cell cross-entropy with an \hlsol{expected regression loss over top-$K$ hypotheses}, plus a \hlsol{physics-consistency term} computed by \hlsol{differentiable bilinear sampling} of precomputed radio maps.
At inference, the hypothesis weights provide calibrated confidence and support optional \hlsol{physics-only refinement} by gradient descent on the physics loss (a posterior density term is optional but not used in our current implementation).
We detail the model end-to-end from first principles, including the induced invariances, the hypothesis scoring semantics of the heads, and the differentiable physics coupling.
\end{abstract}

% ---------------------------------------------
\begin{figure}[t]
\centering
\begin{tikzpicture}[
  node distance=1.15cm,
  >=Latex,
  font=\small,
  block/.style={draw, rounded corners, align=center, minimum width=3.2cm, minimum height=0.9cm},
  arrow/.style={->, thick}
]
\node[block] (gis) {GIS / OSM\\(bbox or city)};
\node[block, right=1.9cm of gis] (scene) {Scene generation\\(tiling \& TX placement)};
\node[block, right=1.9cm of scene] (rt) {Differentiable ray tracing\\(Sionna RT)};
\node[block, below=1.35cm of rt] (data) {Dataset (LMDB)\\$\{(\mathcal{X},\mathcal{M},\mathbf{y})\}$};
\node[block, left=1.9cm of data] (train) {Training\\$\min_\theta~\mathcal{L}_{\text{data}}$\\$+\lambda_{\text{phys}}\,\mathcal{L}_{\text{phys}}$};
\node[block, left=1.9cm of train] (infer) {Inference\\hypotheses \& confidence\\+ optional refinement};

\draw[arrow] (gis) -- (scene);
\draw[arrow] (scene) -- (rt);
\draw[arrow] (rt) -- node[right, align=left] {radio map $\mathbf{R}$\\semantic map $\mathbf{O}$\\measurements $\mathcal{X}$} (data);
\draw[arrow] (data) -- (train);
\draw[arrow] (train) -- (infer);
\end{tikzpicture}
\vspace{-0.2cm}
\caption{End-to-end pipeline: GIS/OSM $\rightarrow$ scenes and deployments $\rightarrow$ differentiable RT $\rightarrow$ dataset $\rightarrow$ training $\rightarrow$ probabilistic inference with optional refinement.}
\label{fig:pipeline}
\end{figure}

% ---------------------------------------------
\section{Introduction}

UE localization from sparse radio measurements under complex urban propagation is central to digital twins, network planning, and context-aware communications. Yet it poses two fundamental difficulties.

First, the inverse map from measurements to position is \hlprob{multi-valued}: different locations can generate similar received power/quality patterns due to shadowing, multipath, and limited sampling.
Second, the forward physics is constrained (e.g., occlusion by buildings, diffraction/reflection structure), and \hlprob{purely data-driven regressors can produce predictions that are not physically plausible}.

This work treats localization as \hlsol{probabilistic inference} with explicit environmental conditioning. We assume access to a multi-channel map context $\mathcal{M}$ (semantic GIS layers and/or precomputed radio fields) and a variable-length measurement sequence $\mathcal{X}$. We learn an amortized posterior $p_\theta(\mathbf{y}\mid \mathcal{X},\mathcal{M})$ over UE position $\mathbf{y}\in\R^2$.
To capture multi-modality at scale, we represent the posterior as a \hlsol{coarse-to-fine} \hlsol{top-$K$ re-ranked hypothesis distribution} tied to a coarse spatial grid.
To enforce physics consistency, we add a \hlsol{differentiable radio-map likelihood term}: predicted positions must align with precomputed radio-map features when sampled via bilinear interpolation.
Finally, we expose an optional refinement mechanism: when needed, we optimize a \hlsol{physics-only objective} (a posterior density prior can be added, but is not used in the current implementation).

\paragraph{Contributions.}
\begin{itemize}
\item \hlsol{Map-conditioned Transformer hypothesis distribution.} A dual-encoder architecture (Transformer-based radio encoder with \texttt{[CLS]} pooling + map ViT with optional E(2)-equivariance) fused by multi-query cross-attention.
\item \hlsol{Coarse-to-fine re-ranking head.} A hierarchical discretize-then-refine predictor that scores Top-$K$ cell hypotheses and re-ranks candidate offsets to preserve multi-modality while controlling compute.
\item \hlsol{Differentiable physics coupling.} A physics-consistency loss derived as a negative log-likelihood under a measurement noise model, computed via \hlsol{differentiable sampling} of precomputed radio fields.
\item \hlsol{Physics-only refinement.} An inference-time energy minimization that improves low-confidence predictions using physics consistency (a posterior prior can be added but is not used in the current implementation).
\end{itemize}

% ---------------------------------------------
\section{Related Work}

\textbf{Differentiable radio propagation.}
Differentiable ray tracing enables gradients of propagation quantities with respect to scene and system parameters, supporting inverse problems and end-to-end optimization. Sionna RT provides a differentiable ray tracer for radio propagation modeling and radio-map computation \cite{hoydis2023sionnart,aitaoudia2025sionna_techreport}. RayLoc reformulates localization as an inverse ray-tracing problem with fully differentiable simulation \cite{han2025rayloc}. Unlike fully differentiable localization pipelines that invoke ray tracing during inference, we amortize inference with a neural posterior conditioned on precomputed maps, and optionally apply local physics refinement when needed. WiNeRT explores neural surrogates for wireless ray tracing, aiming for fast differentiable signal rendering \cite{orekondy2023winert}.

\textbf{Radio map estimation and learning with maps.}
CNN-based estimators such as RadioUNet learn to predict pathloss/radio maps from urban context \cite{levie2021radiounet}. Transformer-based estimators have recently shown strong performance and favorable inductive biases for sparse spatial observations; STORM is an attention-based estimator for radio map estimation and active sensing \cite{viet2024storm}, and TransPathNet combines transformer feature extraction with multiscale decoding for indoor pathloss mapping \cite{li2025transpathnet}. Physics-informed neural networks have also been proposed for radio environment mapping by embedding PDE residuals as soft constraints \cite{shahid2025reveal,shahid2025revealmt}.

\textbf{Set-structured and probabilistic prediction.}
Measurement sequences are irregular and naturally set-valued; Deep Sets characterizes permutation-invariant set functions \cite{zaheer2017deepsets}. For multi-modal regression, discrete hypothesis distributions provide a scalable alternative to continuous mixture models. Our method combines these ideas with a permutation-invariant Transformer encoder for radio tokens, map-conditioned attention, and a Top-$K$ re-ranking head coupled to an explicit physics likelihood term.

% ---------------------------------------------
\section{Problem Formulation from First Principles}
\label{sec:problem}

\subsection{Forward model and inverse objective}

Let $\mathcal{E}$ denote the environment (geometry, materials, terrain) and $\mathcal{T}$ the transmitter deployment (sites, antenna patterns, carrier frequency, bandwidth, etc.). For a UE location $\mathbf{y}\in\R^2$ (2D ground plane for simplicity), a physics simulator induces a \emph{forward operator}
\begin{equation}
  \Phi_{\mathcal{E},\mathcal{T}}:\R^2 \rightarrow \R^{C_r}, 
  \qquad \mathbf{r}(\mathbf{y}) = \Phi_{\mathcal{E},\mathcal{T}}(\mathbf{y}),
\end{equation}
where $\mathbf{r}(\mathbf{y})$ is a vector of radio features (e.g., path gain, SNR, SINR, throughput, BLER, ToA/AoA when available). In practice, we precompute $\Phi_{\mathcal{E},\mathcal{T}}$ on a grid to obtain a \emph{radio map} $\mathbf{R}\in\R^{C_r\times H\times W}$ and sample it continuously at arbitrary $\mathbf{y}$ via differentiable interpolation (Sec.~\ref{sec:lookup}).

We observe a sparse sequence of measurement events $\mathcal{X}$ collected over time and potentially across cells/beams. Abstractly, for each event $t\in\{1,\dots,T\}$,
\begin{equation}
  \mathbf{x}_t = (\underbrace{c_t,b_t}_{\text{IDs}},~\underbrace{\tau_t}_{\text{time}},~\underbrace{\mathbf{f}_t}_{\text{features}}),
  \qquad \mathbf{f}_t \in \R^{d},
\end{equation}
where $c_t$ and $b_t$ denote categorical identifiers (cell/beam) and $\mathbf{f}_t$ concatenates multi-layer features (ray-tracing statistics, PHY metrics, MAC metrics, etc.). The inverse goal is to infer $\mathbf{y}$ given $\mathcal{X}$ and map context $\mathcal{M}$:
\begin{equation}
  \text{infer } \mathbf{y}\quad \text{from}\quad (\mathcal{X},\mathcal{M}),
\end{equation}
where $\mathcal{M}$ may include a semantic map $\mathbf{O}\in\R^{C_o\times H\times W}$ and the radio map $\mathbf{R}$ (or a subset of channels). 

A principled approach is Bayesian inference with a posterior $p(\mathbf{y}\mid \mathcal{X},\mathcal{M})$. We learn an amortized approximation $p_\theta(\mathbf{y}\mid \mathcal{X},\mathcal{M})$ expressed as a discrete hypothesis distribution with calibrated confidence.

\subsection{Coordinate system and discretization}

Let the physical extent be the rectangle $\Omega=[x_{\min},x_{\max}]\times[y_{\min},y_{\max}]$ in meters. We discretize $\Omega$ into a $G\times G$ grid of cells $\{\Omega_c\}_{c=1}^{G^2}$ with cell size $s_x=(x_{\max}-x_{\min})/G$ and $s_y=(y_{\max}-y_{\min})/G$.
Let $\mathbf{c}_c\in\R^2$ be the center of cell $\Omega_c$.
Define the cell-index function $c(\mathbf{y})$ as the unique index such that $\mathbf{y}\in\Omega_{c(\mathbf{y})}$, and denote its center by $\mathbf{c}(\mathbf{y})\triangleq\mathbf{c}_{c(\mathbf{y})}$.
We will use a latent cell variable $C\in\{1,\dots,G^2\}$ to build a hierarchical Top-$K$ hypothesis distribution (Sec.~\ref{sec:posterior}).

% ---------------------------------------------
\begin{figure*}[t]
\centering
\begin{tikzpicture}[
    node distance=0.5cm and 0.7cm,
    >=Latex,
    font=\small,
    scale=0.92,
    transform shape,
    % Block styles with colors
    inputbox/.style={draw, rounded corners=2pt, fill=blue!15, minimum width=1.8cm, minimum height=0.55cm, align=center},
    embedbox/.style={draw, rounded corners=2pt, fill=green!15, minimum width=1.4cm, minimum height=0.45cm, align=center, font=\scriptsize},
    projbox/.style={draw, rounded corners=2pt, fill=green!25, minimum width=1.1cm, minimum height=0.38cm, align=center, font=\tiny},
    transformer/.style={draw, rounded corners=4pt, fill=orange!20, minimum width=2.8cm, minimum height=0.8cm, align=center, thick},
    fusionbox/.style={draw, rounded corners=4pt, fill=violet!20, minimum width=3.0cm, minimum height=0.7cm, align=center, thick},
    headbox/.style={draw, rounded corners=2pt, fill=red!15, minimum width=2.2cm, minimum height=0.6cm, align=center},
    outputbox/.style={draw, rounded corners=2pt, fill=teal!20, minimum width=1.8cm, minimum height=0.55cm, align=center},
    mapbox/.style={draw, rounded corners=2pt, fill=cyan!15, minimum width=1.8cm, minimum height=0.55cm, align=center},
    arrow/.style={->, thick, >=Stealth},
    dasharrow/.style={->, thick, >=Stealth, dashed},
    catarrow/.style={->, >=Stealth, green!50!black},
    dimtext/.style={font=\tiny, text=gray},
]

% ============================================
% RADIO ENCODER (Left)
% ============================================
\node[font=\footnotesize\bfseries, blue!70!black] at (-3.0, 5.3) {Radio Encoder};

% Input features
\node[inputbox, font=\scriptsize] (embin) at (-4.8, 4.5) {IDs, Time\\{\tiny cell, beam, $\tau$}};
\node[inputbox, font=\scriptsize] (featsin) at (-2.5, 4.5) {RT/PHY/MAC\\{\tiny 13+8+5=26 dim}};
\node[inputbox, font=\scriptsize] (cfrin) at (-0.5, 4.5) {CSI/CFR\\{\tiny 8×64}};

% Embeddings
\node[embedbox] (embproj) at (-4.8, 3.6) {Embed\\{\tiny →128×3}};
\node[embedbox] (featproj) at (-2.5, 3.6) {Linear\\{\tiny →128×3}};
\node[projbox] (cfrproj) at (-0.5, 3.6) {CSI Enc\\{\tiny Conv1D →128}};

\draw[arrow, blue!60] (embin) -- (embproj);
\draw[arrow, blue!60] (featsin) -- (featproj);
\draw[arrow, cyan!60!black] (cfrin) -- (cfrproj);

% Concatenation
\node[draw, circle, fill=green!40, minimum size=0.4cm, font=\tiny\bfseries] (concat) at (-2.5, 2.8) {$\oplus$};
\node[dimtext] at (-1.5, 2.8) {896-dim};

\draw[catarrow] (embproj.south) |- (concat);
\draw[catarrow] (featproj.south) -- (concat);
\draw[catarrow] (cfrproj.south) |- (concat);

% Projection
\node[projbox, minimum width=1.6cm, fill=green!30] (inputproj) at (-2.5, 2.1) {Linear→512};
\draw[arrow, green!50!black] (concat) -- (inputproj);

% Transformer
\node[transformer] (radioenc) at (-2.5, 1.0) {\textbf{Transformer}\\{\scriptsize 6 layers, 8 heads, Pre-LN}};
\draw[arrow] (inputproj) -- (radioenc);

% CLS token
\node[draw, rounded corners=1pt, fill=orange!30, font=\tiny, minimum width=0.6cm, minimum height=0.3cm] (cls) at (-4.2, 1.5) {[CLS]};
\draw[arrow, orange!60] (cls.south) |- ([yshift=0.1cm]radioenc.north west);

% Output
\node[outputbox, fill=orange!25, font=\scriptsize] (radiocls) at (-2.5, -0.1) {$\mathbf{z}_r \in \mathbb{R}^{512}$};
\draw[arrow, orange!60] (radioenc) -- (radiocls);

% ============================================
% MAP ENCODER (Right)
% ============================================
\node[font=\footnotesize\bfseries, cyan!70!black] at (3.5, 5.3) {Map Encoder};

% Map inputs
\node[mapbox, font=\scriptsize] (radiomap) at (2.5, 4.5) {Radio Map $\mathbf{R}$\\{\tiny [5, 256, 256]}};
\node[mapbox, font=\scriptsize] (osmmap) at (4.8, 4.5) {OSM Map $\mathbf{O}$\\{\tiny [5, 256, 256]}};

% Concat
\node[draw, circle, fill=cyan!40, minimum size=0.4cm, font=\tiny\bfseries] (mapconcat) at (3.65, 3.6) {$\oplus$};
\node[dimtext] at (4.6, 3.6) {10 ch};
\draw[arrow, cyan!60] (radiomap) -- (mapconcat);
\draw[arrow, cyan!60] (osmmap) -- (mapconcat);

% Patch embed
\node[projbox, minimum width=1.6cm, fill=cyan!25] (patchemb) at (3.65, 2.8) {Patch 16×16};
\draw[arrow, cyan!60] (mapconcat) -- (patchemb);

% ViT
\node[transformer, fill=cyan!20] (mapvit) at (3.65, 1.7) {\textbf{ViT (default)}\\{\scriptsize 6 layers, 8 heads}\\{\scriptsize E(2)-ViT optional (p4m)}};
\draw[arrow] (patchemb) -- (mapvit);

% Spatial tokens output
\node[outputbox, fill=cyan!25, font=\scriptsize] (maptokens) at (3.65, 0.5) {$\mathbf{S} \in \mathbb{R}^{256 \times 768}$};
\draw[arrow, cyan!60] (mapvit) -- (maptokens);

% ============================================
% CROSS-ATTENTION FUSION (Center)
% ============================================
\node[fusionbox] (fusion) at (0.5, -1.3) {\textbf{Cross-Attention Fusion}\\{\scriptsize 4 query tokens, 8 heads}};

\draw[arrow, orange!60] (radiocls.south) -- ++(0, -0.35) -| ([xshift=-0.6cm]fusion.north);
\draw[arrow, cyan!60] (maptokens.south) -- ++(0, -0.35) -| ([xshift=0.6cm]fusion.north);

\node[dimtext, left] at (-0.5, -0.5) {Q};
\node[dimtext, right] at (1.5, -0.5) {K,V};

% Fused output
\node[outputbox, fill=violet!25, font=\scriptsize] (fused) at (0.5, -2.4) {$\mathbf{z}_f \in \mathbb{R}^{768}$};
\draw[arrow, violet!60] (fusion) -- (fused);

% ============================================
% PREDICTION HEADS (Bottom)
% ============================================
% Coarse Head
\node[headbox, font=\scriptsize] (coarse) at (-1.8, -3.5) {\textbf{Coarse Head}\\{\tiny MLP → 32×32 grid}};
\draw[arrow] (fused.south) -- ++(0, -0.3) -| (coarse.north);

% Fine Head  
\node[headbox, fill=yellow!25, font=\scriptsize] (fine) at (2.8, -3.5) {\textbf{Fine Head}\\{\tiny Top-K=5 refinement}};
\draw[arrow] (fused.south) -- ++(0, -0.3) -| (fine.north);

% Coarse outputs
\node[outputbox, fill=red!20, font=\scriptsize, minimum width=1.5cm] (heatmap) at (-2.8, -4.6) {$\boldsymbol{\pi}$\\{\tiny [1024]}};
\node[outputbox, fill=red!20, font=\scriptsize, minimum width=1.5cm] (topk) at (-0.8, -4.6) {Top-K\\{\tiny indices}};
\draw[arrow, red!50] (coarse.south) -- ++(0, -0.25) -| (heatmap.north);
\draw[arrow, red!50] (coarse.south) -- ++(0, -0.25) -| (topk.north);

% Arrow from coarse to fine
\draw[dasharrow, red!40] (topk.east) -- ++(0.4, 0) |- ([yshift=-0.15cm]fine.west);

% Fine outputs
\node[outputbox, fill=yellow!25, font=\scriptsize, minimum width=1.3cm] (offsets) at (2.0, -4.6) {$\boldsymbol{\Delta}_k$\\{\tiny offsets}};
\node[outputbox, fill=yellow!25, font=\scriptsize, minimum width=1.3cm] (scores) at (3.6, -4.6) {$s_k$\\{\tiny scores}};
\draw[arrow, yellow!50!orange] (fine.south) -- ++(0, -0.25) -| (offsets.north);
\draw[arrow, yellow!50!orange] (fine.south) -- ++(0, -0.25) -| (scores.north);

% ============================================
% FINAL OUTPUT
% ============================================
\node[outputbox, fill=teal!30, font=\scriptsize, minimum width=4.2cm, minimum height=0.65cm, thick] (finalpos) at (0.5, -5.8) {\textbf{Top-$K$ Hypotheses}\\$\alpha_k = \softmax(\log \pi_k + s_k)$};
\draw[arrow, thick, teal!60] (heatmap.south) |- (finalpos.west);
\draw[arrow, thick, teal!60] (offsets.south) |- (finalpos);
\draw[arrow, thick, teal!60] (scores.south) |- (finalpos.east);

% ============================================
% BACKGROUND BOXES
% ============================================
\begin{scope}[on background layer]
    \node[draw=blue!40, dashed, rounded corners=6pt, fit=(embin)(cfrin)(radioenc)(radiocls), inner sep=6pt, fill=blue!3] {};
    \node[draw=cyan!40, dashed, rounded corners=6pt, fit=(radiomap)(osmmap)(mapvit)(maptokens), inner sep=6pt, fill=cyan!3] {};
\end{scope}

% Feature annotations
\node[font=\tiny, text=gray, align=left, anchor=west] at (5.8, 4.3) {Radio: PathGain, ToA,\\SINR, Throughput, K-Factor};
\node[font=\tiny, text=gray, align=left, anchor=west] at (5.8, 3.4) {OSM: Height, Footprint,\\Roads, DistTrans, Edges};

\end{tikzpicture}
\vspace{-0.2cm}
\caption{\textbf{Model architecture.} The \textcolor{blue!70!black}{Radio Encoder} tokenizes multi-layer measurements (RT, PHY, MAC features + optional CSI/CFR) via learned embeddings and projections, encodes CSI with a 1D conv stack, processes tokens with a 6-layer Transformer, and extracts a global embedding $\mathbf{z}_r$ via a [CLS] token. The \textcolor{cyan!70!black}{Map Encoder} fuses radio and OSM maps (10 channels total) through patch embedding and a standard ViT by default (optional E(2)-equivariant variant), producing spatial tokens $\mathbf{S}$. \textcolor{violet!70!black}{Cross-attention fusion} attends radio queries to map keys/values with 4 learnable query tokens. The \textcolor{red!70!black}{Coarse Head} predicts a 32×32 cell probability distribution, and the \textcolor{yellow!50!orange}{Fine Head} outputs sub-cell offsets and scores for the Top-K cells, yielding a re-ranked \textcolor{teal!70!black}{hypothesis distribution} over 2D position.}
\label{fig:architecture}
\end{figure*}

% ---------------------------------------------
\section{Map-Conditioned Transformer Posterior}
\label{sec:model}

We now specify the model $p_\theta(\mathbf{y}\mid \mathcal{X},\mathcal{M})$ from first principles: representation of inputs, invariances, and the probabilistic head.

\subsection{Radio measurement tokenization and invariances}
\label{sec:radio}

Each measurement event $\mathbf{x}_t=(c_t,b_t,\tau_t,\mathbf{f}_t)$ is mapped to a token $\mathbf{h}_t\in\R^{d_r}$ via learned embeddings and linear projections:
\begin{equation}
\mathbf{h}_t
= W \Big[\, \underbrace{e_c(c_t)}_{\text{cell ID}} \,\Vert\, \underbrace{e_b(b_t)}_{\text{beam ID}} \,\Vert\, \underbrace{\psi(\tau_t;\bm\tau)}_{\text{time}} \,\Vert\, \underbrace{P\,\mathbf{f}_t}_{\text{features}} \,\Vert\, \underbrace{\phi(\mathbf{H}_{\text{cfr}})}_{\text{CSI/CFR}} \Big],
\label{eq:radio_token}
\end{equation}
where $\Vert$ denotes concatenation, $e_c,e_b$ are learned embeddings, $P$ projects continuous features (RT, PHY, MAC measurements), $\psi$ is a time embedding, and $\phi(\mathbf{H}_{\text{cfr}})$ is an optional CSI/CFR encoder applied to the per-sample CFR magnitude tensor $\mathbf{H}_{\text{cfr}}\in\R^{N_c\times F}$.
In our implementation, $\psi$ uses a per-sequence \emph{normalized relative time axis}:
\begin{equation}
  \delta_t = \tau_t-\tau_1,\qquad \bar\delta_t=\frac{\delta_t}{\max_s \delta_s + \varepsilon},\qquad \psi(\tau_t;\bm\tau)=\mathrm{PE}(\bar\delta_t),
  \label{eq:time_norm}
\end{equation}
where $\mathrm{PE}$ is a sinusoidal lookup table (as in standard Transformers \cite{vaswani2017transformer}).

\paragraph{CSI/CFR encoder.}
When channel-state information is available, we encode the CFR magnitude $\mathbf{H}_{\text{cfr}}$ with a lightweight 1D convolutional stack along the frequency axis, followed by global pooling to obtain a fixed-length vector. This embedding is broadcast across all tokens and concatenated as in Eq.~\eqref{eq:radio_token}. If CSI is unavailable, we omit this term (equivalently, use a zero vector), preserving the tokenization structure.

A standard Transformer encoder with self-attention processes the token set $\{\mathbf{h}_t\}_{t=1}^T$ (with padding masks for variable-length sequences) and outputs contextualized embeddings; we use a learnable \texttt{[CLS]} token prepended to the sequence to pool information into a global representation $\mathbf{z}_r\in\R^{d_r}$.

\paragraph{Implementation note: standard Transformer encoder.}
We implement a standard pre-LN Transformer encoder with masked self-attention and a learnable \texttt{[CLS]} token for pooling. We do not use Set Transformer blocks; permutation invariance arises from omitting index-based positional encodings (only time features are used) and aggregating through the \texttt{[CLS]} token.

\begin{proposition}[Time affine invariance of the embedding]
Assume timestamps transform as $\tau_t' = a\,\tau_t + b$ with $a>0$. Then the normalized relative time coordinates $\bar\delta_t$ in Eq.~\eqref{eq:time_norm} are invariant: $\bar\delta_t'=\bar\delta_t$ for all $t$ (up to the stabilizer $\varepsilon$), and therefore $\psi(\tau_t';\bm\tau')=\psi(\tau_t;\bm\tau)$.
\end{proposition}
\noindent This invariance makes the encoder \hlsol{robust to absolute clock shifts and changes in sampling rate}, focusing attention on the \emph{relative temporal structure} of measurements.

\begin{proposition}[Permutation invariance via set encoding]
If the encoder does not use index-based positional encodings (only token-local features such as Eq.~\eqref{eq:radio_token}), then the Transformer is permutation \emph{equivariant} in its token outputs, and the pooled \texttt{[CLS]} representation is permutation \emph{invariant} with respect to the order of measurements.
\end{proposition}
\noindent This aligns with the theory of set functions \cite{zaheer2017deepsets}. In practice, this property is crucial because \hlprob{measurement sequences are irregular and may arrive unordered or with missing entries}.

\subsection{Map encoder: radio + semantic fields}
\label{sec:map}

We represent map context as a multi-channel tensor $\mathbf{M}\in\R^{(C_r+C_o)\times H\times W}$ by early fusion of radio-map channels $\mathbf{R}$ and semantic channels $\mathbf{O}$.
Our implementation provides two encoder options, configurable via the \texttt{use\_e2\_equivariant} flag; the standard ViT is the default, and the E(2)-equivariant variant is optional.

\paragraph{Standard Vision Transformer (default).}
The default encoder is a standard Vision Transformer (ViT) \cite{dosovitskiy2021vit}. The input $\mathbf{M}$ is partitioned into non-overlapping patches, projected to embeddings via a convolutional layer, and processed by a stack of Transformer encoder layers with learned positional embeddings. A prepended \texttt{[CLS]} token aggregates global context, and the spatial patch embeddings form the token sequence $\mathbf{S}\in\R^{N\times d_m}$ passed to the fusion stage. This encoder is computationally efficient and provides strong baselines, but is \emph{not} equivariant to rotations or reflections of the input map.

\paragraph{E(2)-Equivariant Vision Transformer (optional, not default).}
For applications where rotation/reflection invariance is important (e.g., datasets with diverse map orientations), we provide an optional E(2)-Equivariant ViT architecture based on GE-ViT \cite{xu2023evit}.
This encoder explicitly preserves rotational and reflectional symmetries under the discrete group $G=p4m$ (the symmetry group of the square, $|G|=8$).
The input map $\mathbf{M}$ is first partitioned into patches, then mapped from the planar domain to the group domain via a \emph{lifting self-attention} layer:
\begin{equation}
  \mathbf{Z}^{(0)} = \mathrm{LiftAttn}(\mathbf{M}) \in \R^{d_m \times |G| \times H' \times W'},
\end{equation}
which lifts features from $\mathbb{R}^2$ to the semidirect product $\mathbb{R}^2 \rtimes G$.
Subsequent layers employ \emph{group-equivariant self-attention}, ensuring that rotations of the input map result in corresponding permutations of the feature fibers.
Finally, spatial tokens $\mathbf{S}$ are obtained by flattening the group and spatial dimensions, preserving local equivariant structure for the fusion stage.
This option is enabled by setting \texttt{use\_e2\_equivariant: true} in the model configuration but incurs additional computational cost.

\subsection{Cross-attention fusion}
\label{sec:fusion}

We fuse radio and map modalities using \emph{multi-query cross-attention}, where multiple learnable query tokens attend to map spatial tokens, conditioned on the radio embedding.
Specifically, we maintain $K_q$ learnable query tokens $\{\mathbf{q}_i\}_{i=1}^{K_q}$, which are combined with the radio embedding $\mathbf{z}_r$ to form radio-conditioned queries:
\begin{equation}
  \tilde{\mathbf{q}}_i = \mathbf{q}_i + W_{\text{radio}}\,\mathbf{z}_r, \qquad i=1,\dots,K_q.
\end{equation}
These queries attend to the map tokens $\mathbf{S}$ via multi-head cross-attention:
\begin{equation}
  \mathbf{z}_i
  = \underbrace{\mathrm{MHA}\big(Q=\tilde{\mathbf{q}}_i W_Q,\;K=\mathbf{S} W_K,\;V=\mathbf{S} W_V\big)}_{\text{cross-attention}}
  \;\in\;\R^{d_f}, \qquad i=1,\dots,K_q.
\end{equation}
The $K_q$ output embeddings are concatenated and projected to yield the fused representation:
\begin{equation}
  \mathbf{z}_f = W_{\text{agg}}\left[\mathbf{z}_1 \,\|\, \cdots \,\|\, \mathbf{z}_{K_q}\right] \in \R^{d_f}.
  \label{eq:crossattn}
\end{equation}
A residual MLP refines $\mathbf{z}_f$ (standard Transformer block structure \cite{vaswani2017transformer}).
This multi-query design (with $K_q=4$ by default) allows the fusion module to capture multiple aspects of the radio-map relationship simultaneously, providing richer context for the downstream heads than single-query attention.

% ---------------------------------------------
\subsection{Coarse-to-fine hypothesis re-ranking}
\label{sec:posterior}

\paragraph{Hierarchical latent variable view.}
We introduce a discrete latent cell variable $C\in\{1,\dots,G^2\}$ and factor the posterior as
\begin{equation}
  p_\theta(\mathbf{y}\mid \mathcal{X},\mathcal{M})
  = \sum_{c=1}^{G^2} p_\theta(C=c\mid \mathcal{X},\mathcal{M})~p_\theta(\mathbf{y}\mid C=c,\mathcal{X},\mathcal{M}).
  \label{eq:hier_posterior}
\end{equation}
The coarse head outputs logits over cells and a categorical distribution
\begin{equation}
  \pi_c \,=\, p_\theta(C=c\mid\mathcal{X},\mathcal{M}) = \softmax(\mathbf{u})_c,\qquad \mathbf{u}=\mathrm{MLP}_{\text{coarse}}(\mathbf{z}_f).
  \label{eq:coarse_pi}
\end{equation}

\paragraph{Cell-conditioned refinement.}
For each cell $c$, the fine head predicts an offset and a score conditioned on the fused embedding, a 2D sinusoidal encoding of the cell index, and an optional local map patch embedding:
\begin{equation}
  \phi(c)=\mathrm{PE}_{2D}(r_c,q_c),\qquad
  \ell_c=\mathrm{MapEnc}\!\left(\mathrm{crop}(\mathbf{M}, \mathbf{c}_c, P)\right),
  \label{eq:fine_map_patch}
\end{equation}
\begin{equation}
  [\tilde{\boldsymbol{\Delta}}_c, s_c]
  = f_{\text{fine}}\big([\mathbf{z}_f \Vert \phi(c) \Vert \ell_c]\big),
  \label{eq:fine_refiner}
\end{equation}
\begin{equation}
  \boldsymbol{\Delta}_c = \gamma\,\tanh(\tilde{\boldsymbol{\Delta}}_c)\odot \mathbf{s},
  \qquad
  \mathbf{y}_c = \mathbf{c}_c + \boldsymbol{\Delta}_c,
  \label{eq:fine_bounds}
\end{equation}
where $(r_c,q_c)$ are the row/column indices of cell $c$, $P$ is the local patch size, $\mathbf{s}=(s_x,s_y)$ is the cell size, $\odot$ denotes elementwise scaling, and $\ell_c=\mathbf{0}$ when local map conditioning is disabled.

\paragraph{Top-$K$ re-ranking.}
We retain the top-$K$ most likely cells $\{c_k\}_{k=1}^K$ under $\bm\pi$ and compute re-ranking logits
\begin{equation}
  \ell_k = \log \pi_{c_k} + s_{c_k},\qquad
  \alpha_k = \softmax(\bm\ell)_k,
  \label{eq:topk_rerank}
\end{equation}
yielding a discrete hypothesis distribution
\begin{equation}
  q_{\theta,K}(\mathbf{y}\mid \mathcal{X},\mathcal{M})
  = \sum_{k=1}^K \alpha_k\,\delta(\mathbf{y}-\mathbf{y}_{c_k}).
  \label{eq:topk_discrete}
\end{equation}
This preserves multi-modality while keeping computation bounded.

\section{Learning Objective and Physics Coupling}
\label{sec:loss}

Training must (i) concentrate probability mass on the correct region of $\Omega$, (ii) learn multi-modal re-ranking, and (iii) respect the propagation constraints encoded by the radio maps. We therefore combine a \emph{coarse} classification term, a \emph{fine} expected regression loss, and a \emph{physics} consistency term.
\noindent We abbreviate the supervised data term as $\mathcal{L}_{\text{data}}\triangleq \lambda_{\text{coarse}}\,\mathcal{L}_{\text{coarse}} + \lambda_{\text{fine}}\,\mathcal{L}_{\text{fine}}$.

\subsection{Coarse supervision on the latent cell}
\label{sec:coarse_loss}

Given a ground-truth position $\mathbf{y}^\star$, define the corresponding cell index
\begin{equation}
  c^\star \triangleq c(\mathbf{y}^\star)\in\{1,\dots,G^2\}.
\end{equation}
The coarse head outputs $\bm\pi$ (Eq.~\eqref{eq:coarse_pi}). We apply the standard cross-entropy / negative log-likelihood
\begin{equation}
  \mathcal{L}_{\text{coarse}}(\theta)
  = -\log \pi_{c^\star}.
  \label{eq:coarse_ce}
\end{equation}
This term is particularly important with top-$K$ routing: if the true cell is not in the selected set, gradients from the fine loss alone may be weak or absent for the coarse logits. Eq.~\eqref{eq:coarse_ce} ensures the gating distribution learns to place mass near the correct region.

\subsection{Fine top-$K$ expected regression loss}
\label{sec:topk_loss}

Given the top-$K$ hypotheses $\{\mathbf{y}_{c_k}\}_{k=1}^K$ and weights $\alpha_k$ (Eq.~\eqref{eq:topk_rerank}), we minimize the expected regression error
\begin{equation}
  \mathcal{L}_{\text{fine}}(\theta)
  = \sum_{k=1}^K \alpha_k\,\ell\big(\mathbf{y}^\star, \mathbf{y}_{c_k}\big),
  \label{eq:topk_expected}
\end{equation}
where $\ell$ is a Smooth-L1 loss. This objective encourages at least one hypothesis to align with the ground truth while preserving multi-modality through the re-ranking weights.

\subsection{Differentiable radio-map lookup}
\label{sec:lookup}

To couple predictions to physics, we require a differentiable map $\mathbf{y}\mapsto \mathbf{r}(\mathbf{y})$ extracted from the precomputed radio map $\mathbf{R}$.
Let $\mathbf{R}$ be defined over a grid in $\Omega$ with resolution $\Delta$ meters/pixel.
We define $\mathrm{sample}(\mathbf{R},\mathbf{y})$ as bilinear interpolation of each channel at location $\mathbf{y}$.
In implementation, this is realized by mapping $\mathbf{y}$ to normalized coordinates in $[-1,1]^2$ and applying a differentiable sampler (e.g., \texttt{grid\_sample}).

Formally, for channel $j\in\{1,\dots,C_r\}$,
\begin{equation}
  r_j(\mathbf{y}) = \sum_{p\in\mathcal{N}(\mathbf{y})} w_p(\mathbf{y})~R_j[p],
\end{equation}
where $\mathcal{N}(\mathbf{y})$ are the four neighboring grid points and $w_p(\mathbf{y})$ are bilinear weights. This map is piecewise differentiable in $\mathbf{y}$, enabling gradient-based refinement (Sec.~\ref{sec:refine}).

\subsection{Physics-consistency loss as a likelihood term}
\label{sec:physloss}

Let $\mathbf{m}\in\R^{C_{\text{phys}}}$ denote a vector of observed features extracted from $\mathcal{X}$ that correspond to channels in the radio map (e.g., $\{\text{path gain, SNR, SINR, throughput, BLER}\}$). Let $\mathbf{r}(\mathbf{y})\in\R^{C_{\text{phys}}}$ denote the corresponding radio-map features sampled at $\mathbf{y}$. A simple measurement model is
\begin{equation}
  \mathbf{m} = \mathbf{r}(\mathbf{y}) + \bm\epsilon,\qquad \bm\epsilon \sim \mathcal{N}(\mathbf{0},\diag(\bm\sigma_{\text{phys}}^2)).
  \label{eq:phys_noise}
\end{equation}
The negative log-likelihood (up to constants) yields a weighted squared residual:
\begin{equation}
  -\log p(\mathbf{m}\mid \mathbf{y},\mathbf{R})
  \;\propto\;
  \sum_{j=1}^{C_{\text{phys}}} \frac{(m_j-r_j(\mathbf{y}))^2}{\sigma_{\text{phys},j}^2}
  \;=\;
  \big\| W_{\text{phys}}(\mathbf{m}-\mathbf{r}(\mathbf{y}))\big\|_2^2,
  \label{eq:phys_nll}
\end{equation}
with $W_{\text{phys}}=\diag(\sigma_{\text{phys},j}^{-1})$. This motivates the physics loss
\begin{equation}
  \mathcal{L}_{\text{phys}}(\mathbf{y})
  = \big\| W_{\text{phys}}(\mathbf{m}-\mathbf{r}(\mathbf{y}))\big\|_2^2,
  \label{eq:phys_loss}
\end{equation}
optionally replaced by a robust penalty (e.g., Huber) to reduce sensitivity to outliers or systematic simulator--measurement mismatch.

\paragraph{Implementation note: feature normalization.}
Normalizing each feature channel by its empirical mean and standard deviation (as done in our code) is equivalent to using a diagonal covariance estimate in Eq.~\eqref{eq:phys_noise} and improves conditioning of the refinement gradients.

\subsection{Total objective and optimization}
\label{sec:total_loss}

Let $\theta$ denote all neural parameters. We minimize
\begin{equation}
  \min_\theta~ 
  \lambda_{\text{coarse}}\,\E\!\left[\mathcal{L}_{\text{coarse}}(\theta)\right]
  + \lambda_{\text{fine}}\,\E\!\left[\mathcal{L}_{\text{fine}}(\theta)\right]
  + \lambda_{\text{phys}}\,\E\!\left[\mathcal{L}_{\text{phys}}\big(\hat{\mathbf{y}}_\theta(\mathcal{X},\mathcal{M})\big)\right],
  \label{eq:total_loss}
\end{equation}
where $\hat{\mathbf{y}}_\theta$ is a point estimate extracted from the posterior (Sec.~\ref{sec:inference}) and expectations are over the training distribution of $(\mathcal{X},\mathcal{M},\mathbf{y}^\star)$. The weights $\lambda_{\text{coarse}},\lambda_{\text{fine}},\lambda_{\text{phys}}$ control the relative influence of gating accuracy, probabilistic calibration, and physical consistency.


\section{Inference and MAP Refinement}
\label{sec:inference}

\subsection{Point prediction}

From the Top-$K$ hypothesis distribution $q_{\theta,K}$ we can extract:
\begin{itemize}
\item \textbf{Best hypothesis:} $\hat{\mathbf{y}}_{\text{MAP}}=\mathbf{y}_{c_{k^\star}}$ with $k^\star=\argmax_k \alpha_k$.
\item \textbf{Weighted mean:} $\hat{\mathbf{y}}_{\text{mean}}=\sum_{k=1}^K \alpha_k\,\mathbf{y}_{c_k}$.
\end{itemize}
The best-hypothesis prediction is robust for multi-modal distributions (it chooses a single hypothesis), while the posterior mean can be biased toward ``in-between'' regions when hypotheses are far apart.

\subsection{Physics-only refinement via energy minimization}
\label{sec:refine}

The physics loss enables test-time refinement. In our current implementation we use physics-only refinement:
\begin{equation}
  \mathcal{E}(\mathbf{y}) = \mathcal{L}_{\text{phys}}(\mathbf{y}),
  \label{eq:refine_energy}
\end{equation}
An optional extension adds a posterior prior via $-\log q_{\theta,K}(\mathbf{y}\mid\mathcal{X},\mathcal{M})$, yielding a composite MAP objective that keeps refined solutions in high-density regions of the learned posterior.

\begin{algorithm}[t]
\caption{Optional test-time refinement (per sample)}
\label{alg:refine}
\begin{algorithmic}[1]
\Require hypothesis parameters $\{\alpha_k, \mathbf{y}_{c_k}\}_{k=1}^K$, observed features $\mathbf{m}$, radio map $\mathbf{R}$
\State initialize $\mathbf{y}^{(0)} \gets \mathbf{y}_{c_{k^\star}}$ where $k^\star=\argmax_k \alpha_k$
\For{$i=0,1,\dots,S-1$}
  \State $\mathbf{g}^{(i)} \gets \nabla_{\mathbf{y}} \mathcal{E}(\mathbf{y}^{(i)})$ using Eq.~\eqref{eq:refine_energy} and differentiable lookup
  \State $\mathbf{y}^{(i+1)} \gets \Pi_{\Omega}\!\left(\mathbf{y}^{(i)} - \eta\,\mathbf{g}^{(i)}\right)$ \Comment{step size $\eta$, project to extent}
\EndFor
\State \Return refined position $\mathbf{y}^{(S)}$
\end{algorithmic}
\end{algorithm}

Refinement is most useful when the hypothesis weights are diffuse (low confidence) or when small corrections are needed to satisfy propagation constraints. In practice, refinement can be applied conditionally (e.g., only when $\max_k \alpha_k$ falls below a threshold). Refining multiple candidate hypotheses $\{\mathbf{y}_{c_k}\}_{k=1}^K$ and selecting the one with the lowest physics loss is a simple extension that further improves robustness when the posterior is strongly multi-modal.

% ---------------------------------------------
\section{Data Generation Pipeline and Experimental Protocol}
\label{sec:experiments}

\subsection{Synthetic data generation with differentiable ray tracing}

We generate datasets by (i) constructing 3D scenes from GIS/OSM data, (ii) placing transmitter sites according to configurable strategies, and (iii) running differentiable ray tracing to compute dense radio maps and sample sparse measurement sequences. Sionna RT provides GPU-accelerated differentiable ray tracing for radio propagation and supports radio-map computation \cite{hoydis2023sionnart,aitaoudia2025sionna_techreport}. The resulting dataset is stored in an LMDB key-value format to support large-scale training.

\subsection{Inputs and channels}

We use a multi-channel map tensor with $C_r$ radio channels and $C_o$ semantic channels. Example semantic channels include building footprint/height and terrain/road layers; example radio channels include path gain and quality metrics (SNR/SINR/throughput/BLER). The measurement sequence $\mathcal{X}$ includes categorical identifiers (cell/beam) and multi-layer features (RT/PHY/MAC). Missing or padded events are handled by an attention mask.


\begin{table}[t]
\centering
\caption{Model architecture and training hyperparameters. We provide two map encoder options: a standard ViT (default) and an E(2)-equivariant ViT for rotation/reflection invariance. The radio encoder uses a standard Transformer with \texttt{[CLS]} pooling for permutation-invariant sequence encoding.}
\label{tab:hyperparams}
\begin{tabular}{@{}llp{6.2cm}@{}}
\toprule
\textbf{Component} & \textbf{Specification} & \textbf{Intuition / Rationale} \\
\midrule
\multicolumn{3}{l}{\textit{Data \& Context}} \\
Map resolution & $256\times 256$ & Covers $\sim$1\,km$^2$ urban area at $\sim$4\,m/px precision. \\
Coarse grid & $32\times 32$ & $1024$ hypotheses; balances classification difficulty with spatial resolution. \\
Max sequence & $T=20$ & Sufficient to capture movement trends without high memory cost. \\
\midrule
\multicolumn{3}{l}{\textit{Neural Architecture}} \\
Radio Encoder & \begin{tabular}[t]{@{}l@{}}$d_r=256$, $L=4$, $H=8$\\\texttt{[CLS]} pooling\end{tabular} & \textbf{Standard Transformer:} Processes radio token sets with self-attention. \texttt{[CLS]} token provides permutation-invariant pooling. \\
Map Encoder & \begin{tabular}[t]{@{}l@{}}\textbf{Default:} Standard ViT\\$d_m=384$, $L=6$, $H=6$\\\texttt{patch\_size}=$16$\end{tabular} & \textbf{Efficient:} Standard ViT is computationally efficient and performs well when map orientations are consistent. \\
(Optional, off by default) & \begin{tabular}[t]{@{}l@{}}E2-ViT, \texttt{group}=$p4m$\\$|G|=8$\end{tabular} & \textbf{Equivariant:} E2-ViT (lifting + group attn) ensures rotation/reflection invariance; higher compute cost. \\
Fusion & \begin{tabular}[t]{@{}l@{}}$d_f=256$, $H=8$\\$K_q=4$ query tokens\end{tabular} & \textbf{Multi-query:} Multiple learnable queries attend to map tokens, conditioned on radio features. \\
Positional Heads & \begin{tabular}[t]{@{}l@{}}Coarse: MLP$\to G^2$\\Fine: 2D pos.\ enc. +\\optional local map patches\\Top-$K$ re-ranking\end{tabular} & \textbf{Hierarchical:} Coarse classification over grid cells; fine head uses 2D cell encoding (and optional local map patches) to predict offsets and scores. \\
\midrule
\multicolumn{3}{l}{\textit{Training}} \\
Top-$K$ size & Top-$K=5$ & Covers primary ambiguous modes (e.g., street canyon reflections) while suppressing noise. \\
Loss weights & $\lambda_{\text{coarse}}=0.5$, $\lambda_{\text{fine}}=1.0$ & Fine expected error is primary; coarse ensures correct cell is in top-$K$. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metrics and ablations}

We recommend reporting (i) median/percentile Euclidean error in meters, (ii) hypothesis entropy or max-weight confidence to assess confidence quality, (iii) calibration curves (optional), and (iv) refinement gain (improvement after Algorithm~\ref{alg:refine}). Key ablations include removing map conditioning, removing physics loss, removing top-$K$ re-ranking (single-mode regression), and removing cell-conditioned fine embeddings.

% ---------------------------------------------
\section{Experimental Results}
\label{sec:results}

We demonstrate the model's ability to leverage radio propagation physics and semantic map context for probabilistic localization. Figure~\ref{fig:map_layers} visualizes the multi-channel inputs used by the map encoder: radio-map channels capture propagation structure (shadowing, reflections), while semantic layers encode building geometry and terrain constraints.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/map_layers.png}
\caption{Input map stack used by the map encoder. The top row shows the five radio-map channels (e.g., path gain, ToA, SNR/SINR, throughput), and the bottom row shows the semantic channels (height/footprint/roads/terrain).}
\label{fig:map_layers}
\end{figure}

Figure~\ref{fig:coarse_to_fine} illustrates the coarse-to-fine posterior: the coarse heatmap highlights candidate grid cells, and the top-$K$ re-ranked hypotheses show weighted candidate positions aligned with map structure.

\begin{figure}[t]
\centering
\begin{subfigure}[t]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/coarse_heatmap.png}
  \caption{Coarse cell distribution with the ground-truth cell/position.}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\linewidth}
  \centering
  \includegraphics[width=\linewidth]{figures/posterior_overlay.png}
  \caption{Top-$K$ hypothesis overlay with weighted candidates and predicted mean.}
\end{subfigure}
\caption{Coarse-to-fine posterior visualization on a representative sample.}
\label{fig:coarse_to_fine}
\end{figure}

We also visualize the optional physics-only refinement step. Figure~\ref{fig:refinement_effect} shows how refinement moves the prediction along radio-map gradients and reduces the error for the shown sample. Figure~\ref{fig:error_distribution} summarizes batch-level error statistics with a histogram, CDF, and box plot.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/refinement_effect.png}
\caption{Physics-only refinement example. The left panel shows the refinement trajectory over the path-gain map, and the right panel compares error before vs.\ after refinement.}
\label{fig:refinement_effect}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/error_distribution.png}
\caption{Batch error distribution: histogram, CDF, and box plot summarizing median and tail behavior.}
\label{fig:error_distribution}
\end{figure}

% ---------------------------------------------
\section{Conclusion and Limitations}

We presented a physics-informed, map-conditioned Transformer for UE localization that outputs a multi-modal hypothesis distribution over position, coupled to a differentiable radio-map likelihood. The model combines amortized inference (fast prediction, confidence) with physics-based consistency (regularization and optional refinement). The modular architecture supports both standard Vision Transformer and E(2)-equivariant encoders for map processing, allowing practitioners to trade off computational cost for rotational invariance as needed.

\paragraph{Limitations and future work.}
Our current formulation relies on precomputed radio maps and therefore inherits simulator bias; bridging the sim-to-real gap (e.g., by learning residual corrections or jointly learning material parameters as in differentiable RT) is an important direction. While we provide an optional E(2)-equivariant map encoder, evaluating its benefits on diverse real-world datasets with varying map orientations remains future work. Additional structured priors and stronger relative positional attention mechanisms are also promising extensions.

% ---------------------------------------------
\appendix

\section{\texorpdfstring{Top-$K$ truncation: approximation discussion}{Top-K truncation: approximation discussion}}
\label{app:topk}

Let $\pi_c$ denote the coarse cell probabilities and $s_c$ the fine scores. The full hypothesis set over all $G^2$ cells would assign logits $\ell_c = \log \pi_c + s_c$ and weights $\alpha_c = \softmax(\ell)_c$. We approximate this by retaining only the top-$K$ cells under $\pi_c$ and renormalizing their logits:
\[
\alpha_k = \frac{\exp(\log \pi_{c_k} + s_{c_k})}{\sum_{j=1}^K \exp(\log \pi_{c_j} + s_{c_j})}.
\]
If the top-$K$ coarse mass dominates (i.e., $\sum_{k=1}^K \pi_{c_k} \approx 1$), this truncation preserves the dominant modes while keeping inference efficient.

% ---------------------------------------------
\begin{thebibliography}{99}

\bibitem{vaswani2017transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N.~Gomez, \L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem{dosovitskiy2021vit}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit, and N.~Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem{zaheer2017deepsets}
M.~Zaheer, S.~Kottur, S.~Ravanbakhsh, B.~P{\'o}czos, R.~Salakhutdinov, and A.~Smola.
\newblock Deep sets.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem{hoydis2023sionnart}
J.~Hoydis, F.~A{\"i}t~Aoudia, S.~Cammerer, M.~Nimier-David, N.~Binder, G.~Marcus, and A.~Keller.
\newblock Sionna RT: Differentiable ray tracing for radio propagation modeling.
\newblock \emph{arXiv:2303.11103}, 2023. Also presented at IEEE Globecom Workshops (GC Wkshps), 2023.

\bibitem{aitaoudia2025sionna_techreport}
F.~A{\"i}t~Aoudia, J.~Hoydis, M.~Nimier-David, S.~Cammerer, and A.~Keller.
\newblock Sionna RT: Technical report.
\newblock \emph{arXiv:2504.21719}, 2025. NVIDIA technical report.

\bibitem{han2025rayloc}
X.~Han, T.~Zheng, T.~X.~Han, and J.~Luo.
\newblock RayLoc: Wireless indoor localization via fully differentiable ray-tracing.
\newblock \emph{arXiv:2501.17881}, 2025.

\bibitem{orekondy2023winert}
T.~Orekondy, P.~Kumar, S.~Kadambi, H.~Ye, J.~Soriaga, and A.~Behboodi.
\newblock WiNeRT: Towards neural ray tracing for wireless channel modelling and differentiable simulations.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2023.

\bibitem{levie2021radiounet}
R.~Levie, \c{C}.~Yapar, G.~Kutyniok, and G.~Caire.
\newblock RadioUNet: Fast radio map estimation with convolutional neural networks.
\newblock \emph{IEEE Transactions on Wireless Communications}, 20(6):4001--4017, 2021.

\bibitem{viet2024storm}
P.~Q.~Viet and D.~Romero.
\newblock Spatial transformers for radio map estimation.
\newblock \emph{arXiv:2411.01211}, 2024.

\bibitem{li2025transpathnet}
X.~Li, R.~Liu, S.~Xu, S.~G.~Razul, and C.~Yuen.
\newblock TransPathNet: A novel two-stage framework for indoor radio map prediction.
\newblock \emph{arXiv:2501.16023}, 2025.

\bibitem{shahid2025reveal}
M.~Shahid, K.~Das, H.~Ushaq, H.~Zhang, J.~Song, D.~Qiao, S.~Babu, Y.~Guan, Z.~Zhu, and A.~Ahmed.
\newblock ReVeal: A physics-informed neural network for high-fidelity radio environment mapping.
\newblock \emph{arXiv:2502.19646}, 2025.

\bibitem{shahid2025revealmt}
M.~Shahid, K.~Das, H.~Ushaq, H.~Zhang, J.~Song, D.~Qiao, S.~Babu, Y.~Guan, Z.~Zhu, and A.~Ahmad.
\newblock ReVeal-MT: A physics-informed neural network for multi-transmitter radio environment mapping.
\newblock \emph{arXiv:2512.04100}, 2025.

\bibitem{xu2023evit}
M.~Xu, et al.
\newblock E(2)-equivariant vision transformer.
\newblock \emph{arXiv preprint}, 2023.

\end{thebibliography}

\end{document}
