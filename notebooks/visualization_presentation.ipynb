{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# UE Localization Pipeline: Visualization Presentation\n",
                "\n",
                "This notebook generates high-quality visualizations for the UE Localization pipeline. The sections are organized as follows:\n",
                "\n",
                "1. **Setup & Data Loading** - Load trained model checkpoint and validation data\n",
                "2. **Input Features** - Table view of radio measurements (RT, PHY, MAC) used by the model\n",
                "3. **Map Layers** - 10-panel grid showing Radio Map (5 channels) and OSM Map (5 channels)\n",
                "4. **Model Predictions** - GMM heatmap overlay showing predicted vs ground truth positions\n",
                "5. **Evaluation Metrics** - Error statistics and distribution analysis (histogram, CDF, box plot)\n",
                "6. **Loss Decomposition** - Coarse heatmap and Top-K cell probability visualization\n",
                "7. **Fine Refinement** - Offset magnitudes, uncertainties, and mixture component ellipses\n",
                "8. **Physics Loss** - Differentiable bilinear resampling and gradient visualization\n",
                "9. **Position Refinement** - Inference-time optimization trajectory and improvement analysis\n",
                "10. **Summary** - Comprehensive dashboard with metrics, losses, and CDF comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import yaml\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from IPython.display import display\n",
                "import importlib\n",
                "\n",
                "# Get the absolute path to project root\n",
                "project_root = Path(\"/home/ubuntu/projects/CellularPositioningResearch\")\n",
                "\n",
                "print(f\"Project root: {project_root}\")\n",
                "print(f\"Current working directory: {os.getcwd()}\")\n",
                "\n",
                "# Change to project root\n",
                "os.chdir(project_root)\n",
                "print(f\"Changed to: {os.getcwd()}\")\n",
                "\n",
                "# Add src to path\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "# Force deep reload of all src modules by removing them from cache first\n",
                "to_remove = [key for key in sys.modules.keys() if key.startswith('src.')]\n",
                "for key in to_remove:\n",
                "    del sys.modules[key]\n",
                "\n",
                "from src.training import UELocalizationLightning\n",
                "from src.datasets.radio_dataset import collate_fn\n",
                "\n",
                "# Set aesthetic style\n",
                "plt.style.use('seaborn-v0_8-paper')\n",
                "sns.set_context(\"talk\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Model and Data\n",
                "\n",
                "We load the trained model from a checkpoint. We patch the configuration to point to a valid dataset for visualization."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0966a318",
            "metadata": {},
            "source": [
                "## 2. Input Features Overview\n",
                "\n",
                "The RadioEncoder processes multi-source temporal measurement sequences from cellular network layers. Below is a comprehensive breakdown of all input features, their shapes, and their role in the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85a188bb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display real input features from a sample in the batch\n",
                "sample_idx = 0\n",
                "measurements = batch['measurements']\n",
                "\n",
                "# Get actual dimensions from the data\n",
                "B = measurements['cell_ids'].shape[0]\n",
                "L = measurements['cell_ids'].shape[1]\n",
                "rt_dim = measurements['rt_features'].shape[-1]\n",
                "phy_dim = measurements['phy_features'].shape[-1]\n",
                "mac_dim = measurements['mac_features'].shape[-1]\n",
                "\n",
                "# Check if CFR is available\n",
                "has_cfr = 'cfr_magnitude' in measurements and measurements['cfr_magnitude'] is not None\n",
                "if has_cfr:\n",
                "    cfr_shape = measurements['cfr_magnitude'].shape\n",
                "    cfr_cells, cfr_subcarriers = cfr_shape[-2], cfr_shape[-1]\n",
                "else:\n",
                "    cfr_cells, cfr_subcarriers = 8, 64\n",
                "\n",
                "# Get sequence length for the sample (count valid measurements)\n",
                "mask = measurements['mask'][sample_idx]\n",
                "valid_seq_len = mask.sum().item()\n",
                "\n",
                "print(\"=\" * 120)\n",
                "print(\"RADIO ENCODER INPUT FEATURES - REAL DATA SAMPLE\")\n",
                "print(\"=\" * 120)\n",
                "print(f\"\\nBatch Configuration:\")\n",
                "print(f\"  • Batch Size: {B}\")\n",
                "print(f\"  • Max Sequence Length: {L}\")\n",
                "print(f\"  • Valid Measurements in Sample {sample_idx}: {valid_seq_len}\")\n",
                "print(f\"  • Model Hidden Dimension: 512\")\n",
                "print(f\"  • Embedding Dimension (d/4): 128\")\n",
                "print(f\"\\n\")\n",
                "\n",
                "# Create detailed feature table with REAL VALUES\n",
                "print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "print(\"│ EMBEDDINGS (Categorical → Learned 128-dim vectors)                                                            │\")\n",
                "print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "\n",
                "# Show first few timesteps\n",
                "timesteps_to_show = min(3, valid_seq_len)\n",
                "for t in range(timesteps_to_show):\n",
                "    cell_id = measurements['cell_ids'][sample_idx, t].item()\n",
                "    beam_id = measurements['beam_ids'][sample_idx, t].item()\n",
                "    timestamp = measurements['timestamps'][sample_idx, t].item()\n",
                "    \n",
                "    print(f\"│ Timestep {t}: Cell ID = {cell_id:<6} | Beam ID = {beam_id:<6} | Timestamp = {timestamp:>8.3f}                        │\")\n",
                "\n",
                "print(\"│   → Each embedded to 128-dim vectors via learned lookup tables                                                │\")\n",
                "print(\"│   → Timestamp uses sinusoidal positional encoding: sin/cos of scaled time                                     │\")\n",
                "print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "\n",
                "print()\n",
                "print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "print(f\"│ RT LAYER FEATURES ({rt_dim} features from Sionna Ray-Tracing) - First valid measurement                               │\")\n",
                "print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "\n",
                "rt_feature_names = [\n",
                "    'Path Gains', 'Path Delays', 'AoA Azimuth', 'AoA Elevation', \n",
                "    'AoD Azimuth', 'AoD Elevation', 'Doppler', 'RMS Delay Spread',\n",
                "    'K-Factor', 'Num Paths', 'ToA', 'Is NLoS', 'RMS Angular Spread'\n",
                "]\n",
                "rt_values = measurements['rt_features'][sample_idx, 0, :rt_dim].cpu().numpy()\n",
                "for i, (name, val) in enumerate(zip(rt_feature_names[:rt_dim], rt_values)):\n",
                "    print(f\"│ [{i:2d}] {name:<25} = {val:>10.4f}                                                           │\")\n",
                "print(\"│   → All 13 features projected to 128-dim via Linear(13→128) + LayerNorm                                       │\")\n",
                "print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "\n",
                "print()\n",
                "print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "print(f\"│ PHY LAYER FEATURES ({phy_dim} features from Physical Layer - FAPI) - First valid measurement                         │\")\n",
                "print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "\n",
                "phy_feature_names = [\n",
                "    'RSRP (dBm)', 'RSRQ', 'SINR (dB)', 'CQI', \n",
                "    'RI', 'PMI', 'Capacity (Mbps)', 'Condition Number'\n",
                "]\n",
                "phy_values = measurements['phy_features'][sample_idx, 0, :phy_dim].cpu().numpy()\n",
                "for i, (name, val) in enumerate(zip(phy_feature_names[:phy_dim], phy_values)):\n",
                "    print(f\"│ [{i:2d}] {name:<25} = {val:>10.4f}                                                           │\")\n",
                "print(\"│   → All 8 features projected to 128-dim via Linear(8→128) + LayerNorm                                         │\")\n",
                "print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "\n",
                "print()\n",
                "print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "print(f\"│ MAC LAYER FEATURES ({mac_dim} features from MAC/RRC) - First valid measurement                                        │\")\n",
                "print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "\n",
                "mac_feature_names = [\n",
                "    'Serving Cell ID', 'Timing Advance', 'Power Headroom (dB)', \n",
                "    'Throughput (Mbps)', 'BLER (%)'\n",
                "]\n",
                "mac_values = measurements['mac_features'][sample_idx, 0, :mac_dim].cpu().numpy()\n",
                "for i, (name, val) in enumerate(zip(mac_feature_names[:mac_dim], mac_values)):\n",
                "    print(f\"│ [{i:2d}] {name:<25} = {val:>10.4f}                                                           │\")\n",
                "print(\"│   → All 5 features projected to 128-dim via Linear(5→128) + LayerNorm                                         │\")\n",
                "print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "\n",
                "print()\n",
                "if has_cfr:\n",
                "    print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "    print(f\"│ CFR (Channel Frequency Response from DMRS) [{cfr_cells}×{cfr_subcarriers}]                                                     │\")\n",
                "    print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "    cfr_data = measurements['cfr_magnitude'][sample_idx].cpu().numpy()\n",
                "    print(f\"│ Shape: [{cfr_cells} cells, {cfr_subcarriers} subcarriers]                                                                      │\")\n",
                "    print(f\"│ Mean magnitude: {cfr_data.mean():>8.4f}  |  Std: {cfr_data.std():>8.4f}  |  Max: {cfr_data.max():>8.4f}                              │\")\n",
                "    print(f\"│ Sample values (first 8 subcarriers of cell 0): {str(cfr_data[0, :8]):<45}  │\")\n",
                "    print(\"│   → Encoded via 1D convolutions along frequency axis → Global pooling → Linear projection to 128-dim       │\")\n",
                "    print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "    print()\n",
                "else:\n",
                "    print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "    print(\"│ CFR (Channel Frequency Response) - NOT AVAILABLE IN THIS DATASET                                              │\")\n",
                "    print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "    print()\n",
                "\n",
                "print(\"┌\" + \"─\" * 118 + \"┐\")\n",
                "print(\"│ ENCODER ARCHITECTURE - DATA FLOW                                                                               │\")\n",
                "print(\"├\" + \"─\" * 118 + \"┤\")\n",
                "print(f\"│ 1. Embeddings + Feature Projections:                                                                          │\")\n",
                "print(f\"│    • Cell ID Embedding:      [B={B}, L={valid_seq_len}] → [B, L, 128]                                                 │\")\n",
                "print(f\"│    • Beam ID Embedding:      [B={B}, L={valid_seq_len}] → [B, L, 128]                                                 │\")\n",
                "print(f\"│    • Timestamp Encoding:     [B={B}, L={valid_seq_len}] → [B, L, 128]  (sinusoidal)                                   │\")\n",
                "print(f\"│    • RT Features Projection: [B={B}, L={valid_seq_len}, {rt_dim}] → [B, L, 128]                                            │\")\n",
                "print(f\"│    • PHY Features Projection:[B={B}, L={valid_seq_len}, {phy_dim}] → [B, L, 128]                                             │\")\n",
                "print(f\"│    • MAC Features Projection:[B={B}, L={valid_seq_len}, {mac_dim}] → [B, L, 128]                                              │\")\n",
                "if has_cfr:\n",
                "    print(f\"│    • CFR Encoding:           [B={B}, {cfr_cells}, {cfr_subcarriers}] → [B, 128] (broadcast to [B, L, 128])                          │\")\n",
                "    num_streams = 7\n",
                "else:\n",
                "    num_streams = 6\n",
                "print(f\"│                                                                                                                │\")\n",
                "print(f\"│ 2. Concatenation:            {num_streams} streams → [B, L, {num_streams}×128={num_streams*128}]                                                    │\")\n",
                "print(f\"│                                                                                                                │\")\n",
                "print(f\"│ 3. Linear Projection:        [B, L, {num_streams*128}] → [B, L, 512]                                                          │\")\n",
                "print(f\"│                                                                                                                │\")\n",
                "print(f\"│ 4. Prepend CLS Token:        [B, L, 512] → [B, L+1, 512]                                                      │\")\n",
                "print(f\"│                                                                                                                │\")\n",
                "print(f\"│ 5. Transformer Encoder:      6 layers, 8 heads, masked self-attention                                         │\")\n",
                "print(f\"│                              [B, L+1, 512] → [B, L+1, 512]                                                     │\")\n",
                "print(f\"│                                                                                                                │\")\n",
                "print(f\"│ 6. Extract CLS Token:        [B, L+1, 512] → [B, 512]  ← Final sequence embedding                             │\")\n",
                "print(\"└\" + \"─\" * 118 + \"┘\")\n",
                "\n",
                "print()\n",
                "print(\"Summary:\")\n",
                "print(f\"  • Input: {rt_dim + phy_dim + mac_dim} raw features + 2 IDs + 1 timestamp\" + (\" + 1 CFR matrix\" if has_cfr else \"\"))\n",
                "print(f\"  • Processing: {num_streams} parallel embedding streams\")\n",
                "print(f\"  • Output: Single 512-dim vector representing the measurement sequence\")\n",
                "print(f\"  • Sequence length: Variable (1 to 20), this sample has {valid_seq_len} valid measurements\")\n",
                "print(\"=\" * 120)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "CHECKPOINT_PATH = \"checkpoints/quick_test/last.ckpt\"\n",
                "BASE_CONFIG_PATH = \"checkpoints/quick_test/training_config.yaml\"\n",
                "\n",
                "# Find a valid dataset\n",
                "PROCESSED_DATA_DIR = Path(\"data/processed/sionna_dataset\")\n",
                "possible_datasets = sorted(list(PROCESSED_DATA_DIR.glob(\"dataset_*.zarr\")))\n",
                "if possible_datasets:\n",
                "    DATASET_PATH = str(possible_datasets[-1]) # Use latest\n",
                "    print(f\"Using dataset: {DATASET_PATH}\")\n",
                "else:\n",
                "    # Fallback\n",
                "    DATASET_PATH = \"data/processed/sionna_dataset_eval/dataset_eval.zarr\"\n",
                "\n",
                "if not os.path.exists(CHECKPOINT_PATH):\n",
                "    print(f\"Warning: Checkpoint {CHECKPOINT_PATH} not found.\")\n",
                "    # Try to find any checkpoint\n",
                "    ckpts = list(Path(\"checkpoints\").rglob(\"*.ckpt\"))\n",
                "    if ckpts:\n",
                "        CHECKPOINT_PATH = str(ckpts[0])\n",
                "        print(f\"Fallback to: {CHECKPOINT_PATH}\")\n",
                "\n",
                "# Patch Config\n",
                "try:\n",
                "    with open(BASE_CONFIG_PATH, 'r') as f:\n",
                "        config = yaml.safe_load(f)\n",
                "    \n",
                "    print(f\"Patching dataset path in config to: {DATASET_PATH}\")\n",
                "    config['dataset']['train_zarr_paths'] = [DATASET_PATH]\n",
                "    if 'test_zarr_path' in config['dataset']:\n",
                "        config['dataset']['test_zarr_path'] = DATASET_PATH\n",
                "    if 'val_zarr_path' in config['dataset']:\n",
                "        config['dataset']['val_zarr_path'] = DATASET_PATH\n",
                "    \n",
                "    TEMP_CONFIG_PATH = \"notebooks/temp_viz_config.yaml\"\n",
                "    with open(TEMP_CONFIG_PATH, 'w') as f:\n",
                "        yaml.dump(config, f)\n",
                "\n",
                "    # Load Model\n",
                "    print(f\"Loading model from: {CHECKPOINT_PATH}\")\n",
                "    model = UELocalizationLightning.load_from_checkpoint(\n",
                "        CHECKPOINT_PATH, \n",
                "        config_path=TEMP_CONFIG_PATH,\n",
                "        strict=False # Allow minor mismatches\n",
                "    )\n",
                "    model.eval()\n",
                "    model.cuda() if torch.cuda.is_available() else model.cpu()\n",
                "\n",
                "finally:\n",
                "    if os.path.exists(TEMP_CONFIG_PATH):\n",
                "        os.remove(TEMP_CONFIG_PATH)\n",
                "\n",
                "# Setup Data\n",
                "# We manually setup the dataloader from the config in the checkpoint\n",
                "val_loader = model.val_dataloader()\n",
                "\n",
                "# Collect multiple batches and find one with diverse positions\n",
                "print(\"Searching for a batch with diverse positions...\")\n",
                "batch_iter = iter(val_loader)\n",
                "best_batch = None\n",
                "best_diversity = 0\n",
                "\n",
                "for batch_idx in range(min(20, len(val_loader))):  # Check up to 20 batches\n",
                "    try:\n",
                "        batch = next(batch_iter)\n",
                "    except StopIteration:\n",
                "        break\n",
                "    \n",
                "    positions = batch['position'].numpy()\n",
                "    # Measure diversity as range in both X and Y\n",
                "    x_range = positions[:, 0].max() - positions[:, 0].min()\n",
                "    y_range = positions[:, 1].max() - positions[:, 1].min()\n",
                "    diversity = x_range + y_range\n",
                "    \n",
                "    if diversity > best_diversity:\n",
                "        best_diversity = diversity\n",
                "        best_batch = batch\n",
                "        best_batch_idx = batch_idx\n",
                "    \n",
                "    # If we found a batch with good diversity, use it\n",
                "    if diversity > 0.2:  # At least 20% of scene covered\n",
                "        print(f\"Found diverse batch at index {batch_idx}\")\n",
                "        break\n",
                "\n",
                "if best_batch is not None:\n",
                "    batch = best_batch\n",
                "    print(f\"Using batch {best_batch_idx} with diversity {best_diversity:.3f}\")\n",
                "else:\n",
                "    print(\"Warning: Could not find diverse batch, using last available\")\n",
                "\n",
                "# Move batch to device\n",
                "device = model.device\n",
                "for k, v in batch.items():\n",
                "    if isinstance(v, torch.Tensor):\n",
                "        batch[k] = v.to(device)\n",
                "    elif isinstance(v, dict):\n",
                "        for sub_k, sub_v in v.items():\n",
                "            if isinstance(sub_v, torch.Tensor):\n",
                "                v[sub_k] = sub_v.to(device)\n",
                "\n",
                "# Show position distribution in this batch\n",
                "positions = batch['position'].cpu().numpy()\n",
                "print(f\"\\nLoaded batch with {positions.shape[0]} samples\")\n",
                "print(f\"Position range in batch:\")\n",
                "print(f\"  X: [{positions[:,0].min():.3f}, {positions[:,0].max():.3f}] (range: {positions[:,0].max() - positions[:,0].min():.3f})\")\n",
                "print(f\"  Y: [{positions[:,1].min():.3f}, {positions[:,1].max():.3f}] (range: {positions[:,1].max() - positions[:,1].min():.3f})\")\n",
                "\n",
                "# Print individual sample positions\n",
                "print(f\"\\nSample positions:\")\n",
                "for i, pos in enumerate(positions):\n",
                "    print(f\"  Sample {i}: ({pos[0]:.4f}, {pos[1]:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Sample Measurement Sequence\n",
                "\n",
                "**Plot: Styled DataFrame Table**\n",
                "\n",
                "Displays the raw radio measurements for a single sample as a colored table. This shows actual measured values from one temporal sequence. Features include:\n",
                "- **Time/Cell ID/Beam ID**: Temporal and spatial identifiers\n",
                "- **RT Features**: Ray-tracing derived measurements (path gains, delays, angles, etc.)\n",
                "- **PHY Features**: Physical layer reports (RSRP, RSRQ, SINR, CQI, etc.)\n",
                "- **MAC Features**: MAC/RRC measurements (timing advance, throughput, etc.)\n",
                "\n",
                "This visualization helps verify data quality and understand the temporal nature of the input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_features(batch, sample_idx=0):\n",
                "    measurements = batch['measurements']\n",
                "    \n",
                "    # Extract data for the sample\n",
                "    mask = measurements['mask'][sample_idx].cpu().numpy()\n",
                "    seq_len = int(mask.sum())  # Only take valid steps\n",
                "    \n",
                "    data = {\n",
                "        'Time': measurements['timestamps'][sample_idx, :seq_len].cpu().numpy(),\n",
                "        'Cell ID': measurements['cell_ids'][sample_idx, :seq_len].cpu().numpy(),\n",
                "        'Beam ID': measurements['beam_ids'][sample_idx, :seq_len].cpu().numpy(),\n",
                "        'Path Gain (dB)': measurements['rt_features'][sample_idx, :seq_len, 0].cpu().numpy(),\n",
                "        'ToA (ns)': measurements['rt_features'][sample_idx, :seq_len, 1].cpu().numpy(),\n",
                "        'SNR (dB)': measurements['phy_features'][sample_idx, :seq_len, 2].cpu().numpy(),\n",
                "        'SINR (dB)': measurements['phy_features'][sample_idx, :seq_len, 3].cpu().numpy(),\n",
                "        'Throughput (Mbps)': measurements['mac_features'][sample_idx, :seq_len, 0].cpu().numpy(),\n",
                "    }\n",
                "    \n",
                "    df = pd.DataFrame(data)\n",
                "    \n",
                "    # Styling\n",
                "    print(f\"Input Feature Sequence (Sample {sample_idx})\")\n",
                "    styled = df.style.background_gradient(cmap='viridis', subset=['Path Gain (dB)', 'SNR (dB)', 'Throughput (Mbps)'])\n",
                "    display(styled)\n",
                "    \n",
                "    return df\n",
                "\n",
                "_ = visualize_features(batch, sample_idx=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Map Layers\n",
                "\n",
                "**Plot: 2×5 Grid of Map Channels**\n",
                "\n",
                "Shows the 10-channel map input to the MapEncoder:\n",
                "\n",
                "**Radio Map (5 channels)**: Ray-tracing derived channel predictions\n",
                "- CH0: Path Loss, CH1: RSRP, CH2: Delay Spread, CH3: K-Factor, CH4: AoA\n",
                "\n",
                "**OSM Map (5 channels)**: OpenStreetMap-derived urban geometry\n",
                "- CH0: Building Height, CH1: Building Footprint, CH2: Roads, CH3: Distance Transform, CH4: Edges\n",
                "\n",
                "These multi-channel maps provide spatial context for the positioning task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_maps(batch, sample_idx=0):\n",
                "    radio_map = batch['radio_map'][sample_idx].cpu().numpy()\n",
                "    osm_map = batch['osm_map'][sample_idx].cpu().numpy()\n",
                "    \n",
                "    # Radio Map Channels: ['Path Gain', 'ToA', 'SNR', 'SINR', 'Throughput']\n",
                "    # OSM Map Channels: ['Height', 'Material', 'Footprint', 'Road', 'Terrain']\n",
                "    # Note: Material (1), Road (3), Terrain (4) are often constant/empty but included for compat\n",
                "    \n",
                "    num_osm_channels = osm_map.shape[0]\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
                "    \n",
                "    # Plot Radio Maps - use origin='lower' so (0,0) is bottom-left matching position coords\n",
                "    radio_titles = ['Path Gain', 'ToA', 'SNR', 'SINR', 'Throughput']\n",
                "    for i in range(5):\n",
                "        im = axes[0, i].imshow(radio_map[i], cmap='inferno', origin='lower')\n",
                "        axes[0, i].set_title(f\"Radio: {radio_titles[i]}\")\n",
                "        axes[0, i].axis('off')\n",
                "        plt.colorbar(im, ax=axes[0, i], fraction=0.046, pad=0.04)\n",
                "\n",
                "    # Plot OSM Maps (all 5 channels for backward compatibility)\n",
                "    osm_titles = ['Height', 'Material', 'Footprint', 'Road', 'Terrain']\n",
                "    for i in range(min(num_osm_channels, 5)):\n",
                "        cmap = 'bone' if i in [0, 2] else 'viridis'\n",
                "        im = axes[1, i].imshow(osm_map[i], cmap=cmap, origin='lower')\n",
                "        axes[1, i].set_title(f\"OSM: {osm_titles[i]}\")\n",
                "        axes[1, i].axis('off')\n",
                "        plt.colorbar(im, ax=axes[1, i], fraction=0.046, pad=0.04)\n",
                "    \n",
                "    # Hide unused subplot axes if fewer channels\n",
                "    for i in range(num_osm_channels, 5):\n",
                "        axes[1, i].axis('off')\n",
                "        axes[1, i].set_title(\"(Not Used)\")\n",
                "    \n",
                "    plt.suptitle(f\"Map Layers (Sample {sample_idx})\", fontsize=16)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_maps(batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0ae5dff0",
            "metadata": {},
            "source": [
                "## 5. Sionna Native 3D Scene Visualization\n",
                "\n",
                "**Plot: Interactive 3D Scene with Radio Map Overlay**\n",
                "\n",
                "Uses Sionna's native rendering engine to visualize:\n",
                "- **3D Building Geometry**: The urban environment from OpenStreetMap\n",
                "- **Radio Map Coverage**: Path gain heatmap overlaid on the ground plane\n",
                "- **Transmitter Locations**: Base station positions in the scene\n",
                "- **UE Position**: Current sample's ground truth location\n",
                "\n",
                "This provides spatial context for understanding the radio propagation environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "904418c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_sionna_3d_scene(batch, sample_idx=0, scene_path=None):\n",
                "    \"\"\"\n",
                "    Render a 3D visualization of the Sionna scene with radio map overlay.\n",
                "    \n",
                "    This uses Sionna's native rendering capabilities to show:\n",
                "    - 3D building geometry\n",
                "    - Radio map coverage (path gain)\n",
                "    - Transmitter and receiver positions\n",
                "    \"\"\"\n",
                "    import io\n",
                "    from PIL import Image\n",
                "    \n",
                "    try:\n",
                "        import sionna as sn\n",
                "        from sionna.rt import Camera, load_scene\n",
                "        \n",
                "        # Try to find and load the scene\n",
                "        if scene_path is None:\n",
                "            # Search recursively for scene.xml files\n",
                "            scenes_dir = Path(\"data/scenes\")\n",
                "            scene_files = list(scenes_dir.rglob(\"scene.xml\"))  # Recursive search\n",
                "            if not scene_files:\n",
                "                scene_files = list(scenes_dir.rglob(\"*.xml\"))\n",
                "            if scene_files:\n",
                "                scene_path = scene_files[0]\n",
                "                print(f\"Found {len(scene_files)} scene files. Using: {scene_path}\")\n",
                "            else:\n",
                "                print(\"No scene files found in data/scenes/. Showing fallback visualization.\")\n",
                "                return visualize_radio_map_3d_fallback(batch, sample_idx)\n",
                "        \n",
                "        # Load scene\n",
                "        print(f\"Loading Sionna scene from: {scene_path}\")\n",
                "        scene = load_scene(str(scene_path))\n",
                "        \n",
                "        # Get scene bounds\n",
                "        try:\n",
                "            bbox = scene.mi_scene.bbox()\n",
                "            x_min, y_min, z_min = bbox.min.x, bbox.min.y, bbox.min.z\n",
                "            x_max, y_max, z_max = bbox.max.x, bbox.max.y, bbox.max.z\n",
                "            cx = (x_min + x_max) / 2\n",
                "            cy = (y_min + y_max) / 2\n",
                "            max_dim = max(x_max - x_min, y_max - y_min)\n",
                "            ground_z = z_min\n",
                "            print(f\"Scene bounds: ({x_min:.1f}, {y_min:.1f}) to ({x_max:.1f}, {y_max:.1f}), size: {max_dim:.1f}m\")\n",
                "        except Exception as e:\n",
                "            print(f\"Could not get scene bounds: {e}\")\n",
                "            cx, cy, ground_z = 0, 0, 0\n",
                "            max_dim = 500\n",
                "        \n",
                "        # Get true position from batch and convert to world coordinates\n",
                "        true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "        sample_extent = batch['sample_extent'][sample_idx].item() if 'sample_extent' in batch else 512.0\n",
                "        \n",
                "        # Convert normalized position to world coordinates (centered at scene center)\n",
                "        ue_x = cx + (true_pos[0] - 0.5) * sample_extent\n",
                "        ue_y = cy + (true_pos[1] - 0.5) * sample_extent\n",
                "        ue_z = ground_z + 1.5  # UE height\n",
                "        \n",
                "        print(f\"UE position (world coords): ({ue_x:.1f}, {ue_y:.1f}, {ue_z:.1f})\")\n",
                "        \n",
                "        # Add UE as receiver\n",
                "        rx = sn.rt.Receiver(\"UE\", position=[float(ue_x), float(ue_y), float(ue_z)])\n",
                "        scene.add(rx)\n",
                "        \n",
                "        # Setup camera - isometric view\n",
                "        iso_dist = max_dim * 0.8\n",
                "        cam_z = ground_z + max_dim * 0.6\n",
                "        \n",
                "        cam = Camera(\n",
                "            position=[float(cx - iso_dist), float(cy - iso_dist), float(cam_z)],\n",
                "            look_at=[float(cx), float(cy), float(ground_z)]\n",
                "        )\n",
                "        \n",
                "        # Ensure we have a transmitter\n",
                "        if len(scene.transmitters) == 0:\n",
                "            tx = sn.rt.Transmitter(\"TX_1\", position=[float(cx), float(cy), float(ground_z + 30)])\n",
                "            scene.add(tx)\n",
                "            print(f\"Added transmitter at ({cx:.1f}, {cy:.1f}, {ground_z + 30:.1f})\")\n",
                "        \n",
                "        scene.tx_array = sn.rt.PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
                "        scene.rx_array = sn.rt.PlanarArray(num_rows=1, num_cols=1, pattern=\"iso\", polarization=\"V\")\n",
                "        \n",
                "        # Generate radio map for visualization\n",
                "        print(\"Generating radio map for visualization (this may take a moment)...\")\n",
                "        solver = sn.rt.RadioMapSolver()\n",
                "        \n",
                "        # Use smaller cell size for faster computation\n",
                "        map_size = min(sample_extent, max_dim)\n",
                "        cell_size = max(5.0, map_size / 100)  # At most 100x100 cells\n",
                "        \n",
                "        radio_map = solver(\n",
                "            scene,\n",
                "            center=[float(cx), float(cy), float(ground_z + 1.5)],\n",
                "            size=[float(map_size), float(map_size)],\n",
                "            cell_size=[cell_size, cell_size],\n",
                "            orientation=[0.0, 0.0, 0.0],\n",
                "            max_depth=3,  # Reduce for faster computation\n",
                "            diffraction=False  # Disable for speed\n",
                "        )\n",
                "        print(\"Radio map generated successfully!\")\n",
                "        \n",
                "        # Create figure for visualization\n",
                "        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
                "        \n",
                "        # 1. Render scene to file and display\n",
                "        ax = axes[0]\n",
                "        ax.set_title(\"3D Scene (Isometric View)\", fontsize=12)\n",
                "        try:\n",
                "            print(\"Rendering 3D scene...\")\n",
                "            # Use render_to_file with a temporary file\n",
                "            import tempfile\n",
                "            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:\n",
                "                tmp_path = tmp.name\n",
                "            \n",
                "            scene.render_to_file(\n",
                "                camera=cam,\n",
                "                filename=tmp_path,\n",
                "                resolution=(512, 384)\n",
                "            )\n",
                "            \n",
                "            # Load and display\n",
                "            img = plt.imread(tmp_path)\n",
                "            ax.imshow(img)\n",
                "            ax.axis('off')\n",
                "            \n",
                "            # Cleanup\n",
                "            os.unlink(tmp_path)\n",
                "            print(\"3D scene render successful!\")\n",
                "        except Exception as e:\n",
                "            print(f\"Plain render failed: {e}\")\n",
                "            ax.text(0.5, 0.5, f\"3D Render unavailable\\n(Mitsuba/GPU required)\", ha='center', va='center', \n",
                "                    transform=ax.transAxes, fontsize=12)\n",
                "            ax.set_facecolor('lightgray')\n",
                "            ax.axis('off')\n",
                "        \n",
                "        # 2. Radio map as 2D heatmap (more reliable than 3D overlay)\n",
                "        ax = axes[1]\n",
                "        ax.set_title(\"Radio Map - Path Gain (dB)\", fontsize=12)\n",
                "        try:\n",
                "            print(\"Extracting radio map for visualization...\")\n",
                "            # Extract path gain from radio map\n",
                "            path_gain = radio_map.path_gain\n",
                "            if hasattr(path_gain, 'numpy'):\n",
                "                path_gain = path_gain.numpy()\n",
                "            \n",
                "            # Convert to dB\n",
                "            path_gain_db = 10 * np.log10(np.maximum(path_gain, 1e-12))\n",
                "            \n",
                "            # Take max over transmitters if multiple\n",
                "            if path_gain_db.ndim > 2:\n",
                "                path_gain_2d = np.max(path_gain_db, axis=0)\n",
                "            else:\n",
                "                path_gain_2d = path_gain_db\n",
                "            \n",
                "            im = ax.imshow(path_gain_2d, cmap='inferno', origin='lower', \n",
                "                          extent=[cx - map_size/2, cx + map_size/2, \n",
                "                                  cy - map_size/2, cy + map_size/2],\n",
                "                          vmin=-120, vmax=-50)\n",
                "            \n",
                "            # Mark UE position\n",
                "            ax.scatter([ue_x], [ue_y], c='lime', s=150, marker='*', \n",
                "                      edgecolors='black', linewidth=1.5, zorder=10, label='UE Position')\n",
                "            \n",
                "            # Mark TX position\n",
                "            ax.scatter([cx], [cy], c='red', s=100, marker='^', \n",
                "                      edgecolors='black', linewidth=1.5, zorder=10, label='Transmitter')\n",
                "            \n",
                "            ax.set_xlabel('X (meters)')\n",
                "            ax.set_ylabel('Y (meters)')\n",
                "            ax.legend(loc='upper right')\n",
                "            plt.colorbar(im, ax=ax, label='Path Gain (dB)')\n",
                "            print(\"Radio map visualization successful!\")\n",
                "        except Exception as e:\n",
                "            print(f\"Radio map visualization failed: {e}\")\n",
                "            ax.text(0.5, 0.5, f\"Radio map extraction failed:\\n{str(e)[:60]}\", \n",
                "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
                "            ax.axis('off')\n",
                "        \n",
                "        scene_name = Path(scene_path).parent.name if scene_path else \"Unknown\"\n",
                "        plt.suptitle(f\"Sionna 3D Scene: {scene_name}\\nUE Position: ({ue_x:.1f}, {ue_y:.1f}) m | Scene Size: {max_dim:.0f}m\", fontsize=14)\n",
                "        plt.tight_layout()\n",
                "        \n",
                "        # Use display() for reliable inline output in Jupyter\n",
                "        from IPython.display import display\n",
                "        display(fig)\n",
                "        plt.close(fig)\n",
                "        \n",
                "        # Cleanup\n",
                "        try:\n",
                "            scene.remove(\"UE\")\n",
                "        except:\n",
                "            pass\n",
                "        \n",
                "        return radio_map\n",
                "        \n",
                "    except ImportError as e:\n",
                "        print(f\"Sionna not available: {e}\")\n",
                "        print(\"Falling back to matplotlib 3D visualization...\")\n",
                "        return visualize_radio_map_3d_fallback(batch, sample_idx)\n",
                "    except Exception as e:\n",
                "        print(f\"Sionna 3D rendering failed: {e}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "        print(\"Falling back to matplotlib 3D visualization...\")\n",
                "        return visualize_radio_map_3d_fallback(batch, sample_idx)\n",
                "\n",
                "\n",
                "def visualize_radio_map_3d_fallback(batch, sample_idx=0):\n",
                "    \"\"\"\n",
                "    Fallback 3D visualization using matplotlib when Sionna rendering is unavailable.\n",
                "    Shows the radio map as a 3D surface plot with the OSM height map.\n",
                "    \"\"\"\n",
                "    from mpl_toolkits.mplot3d import Axes3D\n",
                "    \n",
                "    radio_map = batch['radio_map'][sample_idx].cpu().numpy()\n",
                "    osm_map = batch['osm_map'][sample_idx].cpu().numpy()\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "    \n",
                "    h, w = radio_map.shape[-2:]\n",
                "    x = np.linspace(0, 1, w)\n",
                "    y = np.linspace(0, 1, h)\n",
                "    X, Y = np.meshgrid(x, y)\n",
                "    \n",
                "    # Normalize data for visualization\n",
                "    path_gain = radio_map[0]  # First channel is path gain\n",
                "    path_gain_norm = (path_gain - path_gain.min()) / (path_gain.max() - path_gain.min() + 1e-8)\n",
                "    \n",
                "    # Get building heights from OSM map (first channel)\n",
                "    heights = osm_map[0] if osm_map.shape[0] > 0 else np.zeros((h, w))\n",
                "    heights_norm = (heights - heights.min()) / (heights.max() - heights.min() + 1e-8)\n",
                "    \n",
                "    fig = plt.figure(figsize=(16, 6))\n",
                "    \n",
                "    # 1. 3D Surface plot of radio map\n",
                "    ax1 = fig.add_subplot(121, projection='3d')\n",
                "    surf = ax1.plot_surface(X, Y, path_gain_norm * 0.3, cmap='inferno', alpha=0.8, \n",
                "                            linewidth=0, antialiased=True)\n",
                "    ax1.scatter([true_pos[0]], [true_pos[1]], [0.35], c='lime', s=100, marker='*', \n",
                "                edgecolors='black', zorder=10, label='UE Position')\n",
                "    ax1.set_xlabel('X (normalized)')\n",
                "    ax1.set_ylabel('Y (normalized)')\n",
                "    ax1.set_zlabel('Path Gain (normalized)')\n",
                "    ax1.set_title('Radio Map 3D Surface', fontsize=12)\n",
                "    ax1.view_init(elev=30, azim=-60)\n",
                "    fig.colorbar(surf, ax=ax1, shrink=0.5, label='Path Gain')\n",
                "    \n",
                "    # 2. Combined height + radio map\n",
                "    ax2 = fig.add_subplot(122, projection='3d')\n",
                "    \n",
                "    # Plot building heights as wireframe\n",
                "    ax2.plot_wireframe(X, Y, heights_norm * 0.5, color='gray', alpha=0.3, linewidth=0.5)\n",
                "    \n",
                "    # Overlay radio map as colored surface at ground level\n",
                "    surf2 = ax2.plot_surface(X, Y, np.zeros_like(path_gain_norm), \n",
                "                             facecolors=plt.cm.inferno(path_gain_norm),\n",
                "                             alpha=0.7, linewidth=0)\n",
                "    \n",
                "    ax2.scatter([true_pos[0]], [true_pos[1]], [0.05], c='lime', s=100, marker='*', \n",
                "                edgecolors='black', zorder=10, label='UE Position')\n",
                "    ax2.set_xlabel('X (normalized)')\n",
                "    ax2.set_ylabel('Y (normalized)')\n",
                "    ax2.set_zlabel('Height (normalized)')\n",
                "    ax2.set_title('Buildings + Radio Coverage', fontsize=12)\n",
                "    ax2.view_init(elev=45, azim=-45)\n",
                "    ax2.legend()\n",
                "    \n",
                "    plt.suptitle(f\"3D Visualization (Matplotlib Fallback)\\nUE: ({true_pos[0]:.3f}, {true_pos[1]:.3f})\", \n",
                "                 fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    \n",
                "    # Use display() for reliable inline output in Jupyter\n",
                "    from IPython.display import display\n",
                "    display(fig)\n",
                "    plt.close(fig)\n",
                "    \n",
                "    return None\n",
                "\n",
                "\n",
                "# Run the visualization\n",
                "print(\"=\" * 60)\n",
                "print(\"SIONNA 3D SCENE VISUALIZATION\")\n",
                "print(\"=\" * 60)\n",
                "sionna_radio_map = visualize_sionna_3d_scene(batch, sample_idx=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Predictions vs Ground Truth\n",
                "\n",
                "**Plot: GMM Heatmap Overlay**\n",
                "\n",
                "Visualizes the model's Gaussian Mixture Model prediction:\n",
                "- **Background**: OSM map layers (Height=R, Footprint=G, Road+Terrain=B)\n",
                "- **Overlay**: Turbo colormap showing GMM probability density\n",
                "- **Green Star**: Ground truth position\n",
                "- **Red X**: Predicted position (weighted mean of mixture)\n",
                "- **Dashed Circle**: Uncertainty estimate (σ from top component)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def render_prediction(model, batch, sample_idx=0):\n",
                "    with torch.no_grad():\n",
                "        # Use the model's internal model (UELocalizationModel) directly\n",
                "        outputs = model.model(batch['measurements'], batch['radio_map'], batch['osm_map'])\n",
                "    \n",
                "    # Extract outputs for sample\n",
                "    top_k_indices = outputs['top_k_indices'][sample_idx]\n",
                "    top_k_probs = outputs['top_k_probs'][sample_idx]\n",
                "    fine_offsets = outputs['fine_offsets'][sample_idx]\n",
                "    fine_uncertainties = outputs['fine_uncertainties'][sample_idx]\n",
                "    pred_pos = outputs['predicted_position'][sample_idx].cpu().numpy()\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "    \n",
                "    # Get map dimensions\n",
                "    h, w = batch['radio_map'].shape[-2:]\n",
                "    grid_size = model.model.grid_size\n",
                "    \n",
                "    # Render GMM Heatmap manually using model's coarse head\n",
                "    gmm_heatmap = np.zeros((h, w), dtype=np.float32)\n",
                "    \n",
                "    # For each top-K component, render a gaussian\n",
                "    for k in range(min(5, len(top_k_indices))):\n",
                "        cell_idx = top_k_indices[k].item()\n",
                "        prob = top_k_probs[k].item()\n",
                "        offset = fine_offsets[k].cpu().numpy()\n",
                "        sigma = fine_uncertainties[k].cpu().numpy()  # [σx, σy]\n",
                "        \n",
                "        # Cell center (in normalized coords [0, 1])\n",
                "        # cell_idx is row-major: cell_idx = row * grid_size + col\n",
                "        cell_col = cell_idx % grid_size\n",
                "        cell_row = cell_idx // grid_size\n",
                "        cell_x = (cell_col + 0.5) / grid_size\n",
                "        cell_y = (cell_row + 0.5) / grid_size\n",
                "        \n",
                "        # Add offset (clamped to valid range)\n",
                "        center_x = np.clip(cell_x + offset[0], 0, 1)\n",
                "        center_y = np.clip(cell_y + offset[1], 0, 1)\n",
                "        \n",
                "        # Convert to pixel coordinates (no Y-flip, using origin='lower')\n",
                "        cx_px = center_x * w\n",
                "        cy_px = center_y * h\n",
                "        \n",
                "        # Scale sigma to pixels\n",
                "        sigma_px = np.abs(sigma) * w + 1e-3\n",
                "        \n",
                "        # Create coordinate grids for origin='lower' \n",
                "        # Row 0 is at y=0 (bottom), row h-1 is at y=h (top)\n",
                "        y_grid, x_grid = np.ogrid[:h, :w]\n",
                "        \n",
                "        # Compute Gaussian\n",
                "        gauss = np.exp(-0.5 * ((x_grid - cx_px) / sigma_px[0])**2 \n",
                "                       -0.5 * ((y_grid - cy_px) / sigma_px[1])**2)\n",
                "        gmm_heatmap += prob * gauss\n",
                "    \n",
                "    # Normalize heatmap\n",
                "    if gmm_heatmap.max() > 0:\n",
                "        gmm_heatmap /= gmm_heatmap.max()\n",
                "    \n",
                "    # Prepare visualization\n",
                "    # Background: OSM channels - supports both 5-channel (old) and 2-channel (new) formats\n",
                "    osm_map = batch['osm_map'][sample_idx].cpu().numpy()\n",
                "    bg = np.zeros((h, w, 3))\n",
                "    bg[..., 0] = model._normalize_map(osm_map[0])  # Height (R)\n",
                "    \n",
                "    # Handle both old (5-channel) and new (2-channel) OSM formats\n",
                "    if osm_map.shape[0] >= 5:\n",
                "        # Old format: [Height, Material, Footprint, Road, Terrain]\n",
                "        bg[..., 1] = model._normalize_map(osm_map[2])  # Footprint (G)\n",
                "        bg[..., 2] = model._normalize_map(osm_map[3] + osm_map[4] * 0.5)  # Road+Terrain (B)\n",
                "    elif osm_map.shape[0] >= 2:\n",
                "        # New format: [Height, Footprint]\n",
                "        bg[..., 1] = model._normalize_map(osm_map[1])  # Footprint (G)\n",
                "        bg[..., 2] = 0\n",
                "    \n",
                "    # GMM Overlay\n",
                "    gmm_colored = plt.cm.turbo(gmm_heatmap)\n",
                "    gmm_colored[..., 3] = np.clip(gmm_heatmap * 0.8, 0, 0.8) # Alpha\n",
                "    \n",
                "    # Coordinates (convert normalized [0,1] to pixel coords)\n",
                "    # Using origin='lower' so no Y-flip needed\n",
                "    true_px = true_pos[0] * w\n",
                "    true_py = true_pos[1] * h\n",
                "    pred_px = pred_pos[0] * w\n",
                "    pred_py = pred_pos[1] * h\n",
                "    \n",
                "    # Compute error in meters (using actual scene extent if available)\n",
                "    scene_extent = batch['sample_extent'][sample_idx].item() if 'sample_extent' in batch else 512.0\n",
                "    error_m = np.linalg.norm((true_pos - pred_pos) * scene_extent)\n",
                "    \n",
                "    # Plot with origin='lower' for consistent coordinate system\n",
                "    fig, ax = plt.subplots(figsize=(10, 10))\n",
                "    ax.imshow(bg, origin='lower', extent=[0, w, 0, h])\n",
                "    ax.imshow(gmm_colored, origin='lower', extent=[0, w, 0, h])\n",
                "    \n",
                "    ax.scatter([true_px], [true_py], c='lime', s=150, marker='*', label='Ground Truth', edgecolors='black', zorder=10, linewidth=1.5)\n",
                "    ax.scatter([pred_px], [pred_py], c='red', s=100, marker='x', label='Prediction', linewidth=3, zorder=10)\n",
                "    \n",
                "    # Add uncertainty ellipse (from first component)\n",
                "    sigma = fine_uncertainties[0].cpu().numpy()\n",
                "    sigma_px = np.abs(sigma) * w\n",
                "    circle = plt.Circle((pred_px, pred_py), sigma_px.mean(), color='red', fill=False, linestyle='--', label='Uncertainty', linewidth=2)\n",
                "    ax.add_patch(circle)\n",
                "\n",
                "    ax.set_title(f\"Model Prediction vs Ground Truth (Sample {sample_idx})\\nError: {error_m:.2f} m | True Pos: ({true_pos[0]:.3f}, {true_pos[1]:.3f}) | Pred Pos: ({pred_pos[0]:.3f}, {pred_pos[1]:.3f})\", fontsize=12)\n",
                "    ax.legend(loc='upper right', fontsize=11)\n",
                "    ax.axis('off')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return outputs\n",
                "\n",
                "# Use a sample with position more in the center for better visualization\n",
                "outputs = render_prediction(model, batch, sample_idx=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6095bb6d",
            "metadata": {},
            "source": [
                "## 6. Evaluation Metrics\n",
                "\n",
                "**Plots: Error Distribution Analysis (3 panels)**\n",
                "\n",
                "1. **Error Histogram** - Distribution of localization errors with mean/median lines\n",
                "2. **CDF Plot** - Cumulative distribution with 67th/90th percentile markers\n",
                "3. **Box Plot** - Statistical summary showing quartiles and outliers\n",
                "\n",
                "Key metrics computed: Mean, Median, RMSE, Std, 67th/90th/95th Percentiles, Min/Max"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e51b74f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_evaluation_metrics(model, batch, default_scene_extent=512.0):\n",
                "    \"\"\"Compute comprehensive evaluation metrics for the batch.\"\"\"\n",
                "    with torch.no_grad():\n",
                "        outputs = model.model(batch['measurements'], batch['radio_map'], batch['osm_map'])\n",
                "    \n",
                "    pred_pos = outputs['predicted_position'].cpu().numpy()  # [B, 2] normalized\n",
                "    true_pos = batch['position'].cpu().numpy()  # [B, 2] normalized\n",
                "    \n",
                "    # Get scene extent from batch if available, otherwise use default\n",
                "    if 'sample_extent' in batch:\n",
                "        scene_extent = batch['sample_extent'].cpu().numpy()  # [B]\n",
                "        # Use per-sample extent for error calculation\n",
                "        errors_m = np.linalg.norm((pred_pos - true_pos) * scene_extent[:, None], axis=1)\n",
                "        avg_extent = scene_extent.mean()\n",
                "    else:\n",
                "        scene_extent = default_scene_extent\n",
                "        errors_m = np.linalg.norm((pred_pos - true_pos) * scene_extent, axis=1)\n",
                "        avg_extent = scene_extent\n",
                "    \n",
                "    metrics = {\n",
                "        'Mean Error (m)': np.mean(errors_m),\n",
                "        'Median Error (m)': np.median(errors_m),\n",
                "        'RMSE (m)': np.sqrt(np.mean(errors_m**2)),\n",
                "        'Std Error (m)': np.std(errors_m),\n",
                "        '67th Percentile (m)': np.percentile(errors_m, 67),\n",
                "        '90th Percentile (m)': np.percentile(errors_m, 90),\n",
                "        '95th Percentile (m)': np.percentile(errors_m, 95),\n",
                "        'Max Error (m)': np.max(errors_m),\n",
                "        'Min Error (m)': np.min(errors_m),\n",
                "    }\n",
                "    \n",
                "    return metrics, errors_m, pred_pos, true_pos, avg_extent\n",
                "\n",
                "# Compute metrics\n",
                "metrics, errors_m, pred_pos, true_pos, scene_extent = compute_evaluation_metrics(model, batch)\n",
                "\n",
                "# Display metrics\n",
                "print(\"=\" * 50)\n",
                "print(\"EVALUATION METRICS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"  Scene Extent:            {scene_extent:.1f} m\")\n",
                "for key, value in metrics.items():\n",
                "    print(f\"  {key:25s}: {value:8.3f}\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Print per-sample details\n",
                "print(\"\\nPer-sample details:\")\n",
                "print(f\"{'Sample':>6} | {'True X':>8} {'True Y':>8} | {'Pred X':>8} {'Pred Y':>8} | {'Error (m)':>10}\")\n",
                "print(\"-\" * 65)\n",
                "for i in range(len(errors_m)):\n",
                "    print(f\"{i:>6} | {true_pos[i,0]:>8.4f} {true_pos[i,1]:>8.4f} | {pred_pos[i,0]:>8.4f} {pred_pos[i,1]:>8.4f} | {errors_m[i]:>10.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "78b2ac1a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_error_analysis(errors_m, title=\"Error Distribution\"):\n",
                "    \"\"\"Plot comprehensive error analysis visualizations.\"\"\"\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "    \n",
                "    # 1. Histogram of errors\n",
                "    ax = axes[0]\n",
                "    ax.hist(errors_m, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
                "    ax.axvline(np.median(errors_m), color='red', linestyle='--', linewidth=2, label=f'Median: {np.median(errors_m):.1f}m')\n",
                "    ax.axvline(np.mean(errors_m), color='orange', linestyle='-', linewidth=2, label=f'Mean: {np.mean(errors_m):.1f}m')\n",
                "    ax.set_xlabel('Localization Error (m)', fontsize=12)\n",
                "    ax.set_ylabel('Count', fontsize=12)\n",
                "    ax.set_title('Error Histogram', fontsize=14)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    # 2. CDF Plot\n",
                "    ax = axes[1]\n",
                "    sorted_errors = np.sort(errors_m)\n",
                "    cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
                "    ax.plot(sorted_errors, cdf * 100, linewidth=2, color='steelblue')\n",
                "    ax.axhline(67, color='green', linestyle='--', alpha=0.7, label='67th percentile')\n",
                "    ax.axhline(90, color='orange', linestyle='--', alpha=0.7, label='90th percentile')\n",
                "    ax.set_xlabel('Localization Error (m)', fontsize=12)\n",
                "    ax.set_ylabel('CDF (%)', fontsize=12)\n",
                "    ax.set_title('Cumulative Distribution Function', fontsize=14)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    ax.set_ylim([0, 100])\n",
                "    \n",
                "    # 3. Box Plot\n",
                "    ax = axes[2]\n",
                "    bp = ax.boxplot(errors_m, vert=True, widths=0.6, patch_artist=True)\n",
                "    bp['boxes'][0].set_facecolor('lightsteelblue')\n",
                "    bp['boxes'][0].set_edgecolor('steelblue')\n",
                "    ax.set_ylabel('Localization Error (m)', fontsize=12)\n",
                "    ax.set_title('Error Box Plot', fontsize=14)\n",
                "    ax.set_xticks([1])\n",
                "    ax.set_xticklabels(['All Samples'])\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    \n",
                "    # Add statistics text\n",
                "    stats_text = f\"Median: {np.median(errors_m):.1f}m\\nRMSE: {np.sqrt(np.mean(errors_m**2)):.1f}m\"\n",
                "    ax.text(1.3, np.median(errors_m), stats_text, fontsize=10, verticalalignment='center')\n",
                "    \n",
                "    plt.suptitle(title, fontsize=16, y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Plot error analysis for the batch\n",
                "plot_error_analysis(errors_m, \"Batch Error Analysis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "962f5c1b",
            "metadata": {},
            "source": [
                "## 7. Coarse and Fine Loss Decomposition\n",
                "\n",
                "**Plots: Coarse Head Analysis (2 panels)**\n",
                "\n",
                "The model uses a **coarse-to-fine** approach:\n",
                "\n",
                "$$\\mathcal{L}_{\\text{total}} = \\lambda_{\\text{coarse}} \\mathcal{L}_{\\text{coarse}} + \\lambda_{\\text{fine}} \\mathcal{L}_{\\text{fine}}$$\n",
                "\n",
                "1. **Coarse Heatmap** - Grid cell probabilities with GT cell (green) and Top-K cells (colored borders)\n",
                "2. **Top-K Bar Chart** - Probability distribution over top candidate cells (green = correct)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93e4ff07",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_loss_breakdown(model, batch):\n",
                "    \"\"\"Compute and visualize the coarse and fine loss components.\"\"\"\n",
                "    with torch.no_grad():\n",
                "        outputs = model.model(batch['measurements'], batch['radio_map'], batch['osm_map'])\n",
                "    \n",
                "    targets = {\n",
                "        'position': batch['position'],\n",
                "        'cell_grid': batch['cell_grid'],\n",
                "    }\n",
                "    \n",
                "    loss_weights = {'coarse_weight': 1.0, 'fine_weight': 1.0}\n",
                "    losses = model.model.compute_loss(outputs, targets, loss_weights)\n",
                "    \n",
                "    return losses, outputs\n",
                "\n",
                "losses, outputs = compute_loss_breakdown(model, batch)\n",
                "\n",
                "# Display loss breakdown\n",
                "print(\"=\" * 50)\n",
                "print(\"LOSS BREAKDOWN\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"  Total Loss:         {losses['loss'].item():.4f}\")\n",
                "print(f\"  Coarse Loss (CE):   {losses['coarse_loss'].item():.4f}\")\n",
                "print(f\"  Fine Loss (NLL):    {losses['fine_loss'].item():.4f}\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Visualize the coarse heatmap for a sample\n",
                "def visualize_coarse_heatmap(outputs, batch, sample_idx=0):\n",
                "    \"\"\"Visualize the coarse prediction heatmap and ground truth cell.\"\"\"\n",
                "    coarse_heatmap = outputs['coarse_heatmap'][sample_idx].cpu().numpy()\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "    true_cell = batch['cell_grid'][sample_idx].item()\n",
                "    \n",
                "    grid_size = int(np.sqrt(coarse_heatmap.shape[0])) if coarse_heatmap.ndim == 1 else coarse_heatmap.shape[0]\n",
                "    \n",
                "    # Ensure heatmap is 2D\n",
                "    if coarse_heatmap.ndim == 1:\n",
                "        coarse_heatmap = coarse_heatmap.reshape(grid_size, grid_size)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "    \n",
                "    # 1. Coarse heatmap with true position (using origin='lower' for consistency)\n",
                "    ax = axes[0]\n",
                "    im = ax.imshow(coarse_heatmap, cmap='hot', interpolation='nearest', origin='lower')\n",
                "    \n",
                "    # Mark ground truth cell - cell_idx = row * grid_size + col\n",
                "    # With origin='lower', row 0 is at the bottom\n",
                "    gt_row = true_cell // grid_size  # Y position (row)\n",
                "    gt_col = true_cell % grid_size   # X position (col)\n",
                "    rect = plt.Rectangle((gt_col - 0.5, gt_row - 0.5), 1, 1, fill=False, edgecolor='lime', linewidth=3, label='GT Cell')\n",
                "    ax.add_patch(rect)\n",
                "    \n",
                "    # Mark top-K cells\n",
                "    top_k_indices = outputs['top_k_indices'][sample_idx].cpu().numpy()\n",
                "    top_k_probs = outputs['top_k_probs'][sample_idx].cpu().numpy()\n",
                "    for k, (idx, prob) in enumerate(zip(top_k_indices[:3], top_k_probs[:3])):\n",
                "        k_row = idx // grid_size\n",
                "        k_col = idx % grid_size\n",
                "        color = ['cyan', 'yellow', 'orange'][k]\n",
                "        rect = plt.Rectangle((k_col - 0.5, k_row - 0.5), 1, 1, fill=False, edgecolor=color, linewidth=2, linestyle='--')\n",
                "        ax.add_patch(rect)\n",
                "    \n",
                "    # Add true position marker\n",
                "    ax.scatter(true_pos[0] * grid_size, true_pos[1] * grid_size, c='lime', s=100, marker='*', \n",
                "               edgecolors='black', zorder=10, label='True Pos')\n",
                "    \n",
                "    ax.set_xlabel('X (grid cells)')\n",
                "    ax.set_ylabel('Y (grid cells)')\n",
                "    ax.set_title(f'Coarse Prediction Heatmap (Sample {sample_idx})\\nGT Cell: {true_cell} (row={gt_row}, col={gt_col})', fontsize=12)\n",
                "    plt.colorbar(im, ax=ax, label='Probability')\n",
                "    ax.legend(loc='upper right')\n",
                "    \n",
                "    # 2. Top-K probabilities bar chart\n",
                "    ax = axes[1]\n",
                "    top_k = 5\n",
                "    indices = top_k_indices[:top_k]\n",
                "    probs = top_k_probs[:top_k]\n",
                "    \n",
                "    colors = ['green' if idx == true_cell else 'steelblue' for idx in indices]\n",
                "    bars = ax.bar(range(top_k), probs, color=colors, edgecolor='black')\n",
                "    ax.set_xticks(range(top_k))\n",
                "    ax.set_xticklabels([f'Cell {idx}' for idx in indices], rotation=45, ha='right')\n",
                "    ax.set_ylabel('Probability', fontsize=12)\n",
                "    ax.set_title('Top-K Cell Probabilities\\n(Green = Ground Truth)', fontsize=12)\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    \n",
                "    # Annotate bars\n",
                "    for i, (bar, prob) in enumerate(zip(bars, probs)):\n",
                "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
                "                f'{prob:.3f}', ha='center', va='bottom', fontsize=10)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_coarse_heatmap(outputs, batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c40ae433",
            "metadata": {},
            "source": [
                "## 8. Fine Refinement Head Analysis\n",
                "\n",
                "**Plots: Fine Head Outputs (3 panels)**\n",
                "\n",
                "The Fine Head outputs sub-cell refinements:\n",
                "\n",
                "$$\\hat{\\mathbf{y}} = \\text{CellCenter}(c^*) + \\Delta\\mathbf{y}$$\n",
                "\n",
                "1. **Offset Magnitudes** - Bar chart showing displacement from cell centers (meters)\n",
                "2. **Uncertainties (σx, σy)** - Predicted standard deviations per component\n",
                "3. **Mixture Components** - 2σ ellipses for each GMM component with ground truth star"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fc943b35",
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_fine_refinement(outputs, batch, sample_idx=0, scene_extent=512.0):\n",
                "    \"\"\"Visualize the fine refinement outputs (offsets and uncertainties).\"\"\"\n",
                "    fine_offsets = outputs['fine_offsets'][sample_idx].cpu().numpy()  # [K, 2]\n",
                "    fine_uncertainties = outputs['fine_uncertainties'][sample_idx].cpu().numpy()  # [K, 2]\n",
                "    top_k_indices = outputs['top_k_indices'][sample_idx].cpu().numpy()\n",
                "    top_k_probs = outputs['top_k_probs'][sample_idx].cpu().numpy()\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "    pred_pos = outputs['predicted_position'][sample_idx].cpu().numpy()\n",
                "    \n",
                "    grid_size = model.model.grid_size\n",
                "    cell_size = 1.0 / grid_size  # Normalized cell size\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "    \n",
                "    # 1. Offset magnitudes for each component\n",
                "    ax = axes[0]\n",
                "    offset_magnitudes = np.linalg.norm(fine_offsets, axis=1) * scene_extent  # in meters\n",
                "    bars = ax.bar(range(len(offset_magnitudes)), offset_magnitudes, color='steelblue', edgecolor='black')\n",
                "    ax.set_xticks(range(len(offset_magnitudes)))\n",
                "    ax.set_xticklabels([f'K={i}' for i in range(len(offset_magnitudes))])\n",
                "    ax.set_ylabel('Offset Magnitude (m)', fontsize=12)\n",
                "    ax.set_title('Fine Offset Magnitudes per Component', fontsize=12)\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    ax.axhline(cell_size * scene_extent / 2, color='red', linestyle='--', label=f'Half Cell: {cell_size*scene_extent/2:.1f}m')\n",
                "    ax.legend()\n",
                "    \n",
                "    # 2. Uncertainty (sigma) for each component\n",
                "    ax = axes[1]\n",
                "    sigma_x = np.abs(fine_uncertainties[:, 0]) * scene_extent\n",
                "    sigma_y = np.abs(fine_uncertainties[:, 1]) * scene_extent\n",
                "    x = np.arange(len(sigma_x))\n",
                "    width = 0.35\n",
                "    ax.bar(x - width/2, sigma_x, width, label='σx', color='coral', edgecolor='black')\n",
                "    ax.bar(x + width/2, sigma_y, width, label='σy', color='teal', edgecolor='black')\n",
                "    ax.set_xticks(x)\n",
                "    ax.set_xticklabels([f'K={i}' for i in range(len(sigma_x))])\n",
                "    ax.set_ylabel('Uncertainty σ (m)', fontsize=12)\n",
                "    ax.set_title('Predicted Uncertainties per Component', fontsize=12)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    \n",
                "    # 3. Visualize mixture components on a zoomed view\n",
                "    ax = axes[2]\n",
                "    \n",
                "    # Plot each mixture component as an ellipse\n",
                "    from matplotlib.patches import Ellipse\n",
                "    \n",
                "    colors = plt.cm.tab10(np.linspace(0, 1, len(top_k_indices)))\n",
                "    for k, (idx, prob, offset, sigma, color) in enumerate(zip(top_k_indices, top_k_probs, fine_offsets, fine_uncertainties, colors)):\n",
                "        # Cell center (normalized) - idx = row * grid_size + col\n",
                "        col = idx % grid_size\n",
                "        row = idx // grid_size\n",
                "        cx = (col + 0.5) * cell_size  # X = column\n",
                "        cy = (row + 0.5) * cell_size  # Y = row\n",
                "        \n",
                "        # Apply offset\n",
                "        px = cx + offset[0]\n",
                "        py = cy + offset[1]\n",
                "        \n",
                "        # Draw ellipse (2-sigma)\n",
                "        ellipse = Ellipse((px, py), 2 * np.abs(sigma[0]), 2 * np.abs(sigma[1]), \n",
                "                          fill=False, edgecolor=color, linewidth=2, \n",
                "                          linestyle='-' if k == 0 else '--',\n",
                "                          label=f'K={k}: p={prob:.2f}')\n",
                "        ax.add_patch(ellipse)\n",
                "        ax.scatter(px, py, c=[color], s=50, marker='o', zorder=5)\n",
                "    \n",
                "    # Mark true position\n",
                "    ax.scatter(true_pos[0], true_pos[1], c='lime', s=150, marker='*', \n",
                "               edgecolors='black', zorder=10, label='Ground Truth')\n",
                "    \n",
                "    # Mark predicted position (weighted mean)\n",
                "    ax.scatter(pred_pos[0], pred_pos[1], c='red', s=100, marker='x', \n",
                "               linewidth=3, zorder=10, label='Prediction')\n",
                "    \n",
                "    ax.set_xlim([0, 1])\n",
                "    ax.set_ylim([0, 1])\n",
                "    ax.set_aspect('equal')\n",
                "    ax.set_xlabel('X (normalized)', fontsize=12)\n",
                "    ax.set_ylabel('Y (normalized)', fontsize=12)\n",
                "    ax.set_title('Mixture Components (2σ Ellipses)', fontsize=12)\n",
                "    ax.legend(loc='upper right', fontsize=9)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Print diagnostic info\n",
                "    print(f\"True position: ({true_pos[0]:.4f}, {true_pos[1]:.4f})\")\n",
                "    print(f\"Predicted position: ({pred_pos[0]:.4f}, {pred_pos[1]:.4f})\")\n",
                "    print(f\"Error: {np.linalg.norm(true_pos - pred_pos) * scene_extent:.2f} m\")\n",
                "\n",
                "visualize_fine_refinement(outputs, batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09f5d5dd",
            "metadata": {},
            "source": [
                "## 9. Physics Loss & Differentiable Bilinear Resampling\n",
                "\n",
                "**Plots: Bilinear Sampling Visualization (3 panels)**\n",
                "\n",
                "The Physics Loss enforces consistency using differentiable interpolation:\n",
                "\n",
                "$$\\mathcal{L}_{\\text{phys}} = \\sum_{f \\in \\mathcal{F}} w_f \\left\\| m_f^{\\text{obs}} - R_f(\\hat{\\mathbf{x}}) \\right\\|^2$$\n",
                "\n",
                "1. **Original Radio Map** - Path Gain channel with true/predicted positions marked\n",
                "2. **Bilinear Resampled** - 50×50 grid showing interpolated values\n",
                "3. **Gradient Magnitude** - |∇f| with quiver arrows showing gradient direction\n",
                "\n",
                "This enables backpropagation through the position → feature lookup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4004a3ac",
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.physics_loss import differentiable_lookup, normalize_coords, PhysicsLoss, PhysicsLossConfig\n",
                "\n",
                "def demonstrate_bilinear_resampling(batch, sample_idx=0):\n",
                "    \"\"\"Demonstrate differentiable bilinear interpolation from radio maps.\"\"\"\n",
                "    radio_map = batch['radio_map'][sample_idx:sample_idx+1]  # [1, C, H, W]\n",
                "    true_pos = batch['position'][sample_idx:sample_idx+1]  # [1, 2] normalized\n",
                "    \n",
                "    # Map extent (normalized coordinates)\n",
                "    map_extent = (0.0, 0.0, 1.0, 1.0)\n",
                "    \n",
                "    # Sample features at true position\n",
                "    sampled_features = differentiable_lookup(true_pos, radio_map, map_extent)\n",
                "    \n",
                "    print(\"=\" * 60)\n",
                "    print(\"DIFFERENTIABLE BILINEAR RESAMPLING DEMONSTRATION\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"\\nTrue Position (normalized): [{true_pos[0, 0].item():.4f}, {true_pos[0, 1].item():.4f}]\")\n",
                "    print(f\"Radio Map Shape: {radio_map.shape}\")\n",
                "    print(f\"\\nSampled Features at True Position:\")\n",
                "    \n",
                "    feature_names = ['Path Gain', 'ToA', 'AoA', 'SNR', 'SINR']\n",
                "    for i, (name, val) in enumerate(zip(feature_names, sampled_features[0].cpu().numpy())):\n",
                "        print(f\"  {name:12s}: {val:.4f}\")\n",
                "    \n",
                "    return sampled_features, radio_map\n",
                "\n",
                "sampled_features, radio_map_sample = demonstrate_bilinear_resampling(batch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b4a1d781",
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_bilinear_sampling(batch, sample_idx=0):\n",
                "    \"\"\"Visualize the bilinear sampling process on the radio map.\"\"\"\n",
                "    radio_map = batch['radio_map'][sample_idx].cpu().numpy()  # [C, H, W]\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()  # [2]\n",
                "    pred_pos = outputs['predicted_position'][sample_idx].cpu().numpy()\n",
                "    \n",
                "    h, w = radio_map.shape[-2:]\n",
                "    \n",
                "    # Sample grid of positions\n",
                "    grid_x = np.linspace(0, 1, 50)\n",
                "    grid_y = np.linspace(0, 1, 50)\n",
                "    xx, yy = np.meshgrid(grid_x, grid_y)\n",
                "    sample_positions = torch.tensor(np.stack([xx.flatten(), yy.flatten()], axis=1), dtype=torch.float32)\n",
                "    \n",
                "    # Expand radio map for batch\n",
                "    radio_map_tensor = batch['radio_map'][sample_idx:sample_idx+1].expand(len(sample_positions), -1, -1, -1)\n",
                "    \n",
                "    # Sample features at all positions\n",
                "    sampled = differentiable_lookup(sample_positions.to(batch['radio_map'].device), \n",
                "                                    radio_map_tensor, \n",
                "                                    (0.0, 0.0, 1.0, 1.0))\n",
                "    \n",
                "    # Reshape for visualization (using first feature - path gain)\n",
                "    sampled_map = sampled[:, 0].cpu().numpy().reshape(50, 50)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
                "    \n",
                "    # 1. Original radio map (Path Gain)\n",
                "    ax = axes[0]\n",
                "    im = ax.imshow(radio_map[0], cmap='inferno', origin='lower')\n",
                "    ax.scatter(true_pos[0] * w, true_pos[1] * h, c='lime', s=100, marker='*', \n",
                "               edgecolors='black', label='True Pos', zorder=10)\n",
                "    ax.scatter(pred_pos[0] * w, pred_pos[1] * h, c='red', s=80, marker='x', \n",
                "               linewidth=3, label='Pred Pos', zorder=10)\n",
                "    ax.set_title('Original Radio Map (Path Gain)', fontsize=12)\n",
                "    plt.colorbar(im, ax=ax)\n",
                "    ax.legend()\n",
                "    \n",
                "    # 2. Resampled via bilinear interpolation\n",
                "    ax = axes[1]\n",
                "    im = ax.imshow(sampled_map, cmap='inferno', origin='lower', extent=[0, 1, 0, 1])\n",
                "    ax.scatter(true_pos[0], true_pos[1], c='lime', s=100, marker='*', \n",
                "               edgecolors='black', label='True Pos', zorder=10)\n",
                "    ax.scatter(pred_pos[0], pred_pos[1], c='red', s=80, marker='x', \n",
                "               linewidth=3, label='Pred Pos', zorder=10)\n",
                "    ax.set_title('Bilinear Resampled (50x50 grid)', fontsize=12)\n",
                "    plt.colorbar(im, ax=ax)\n",
                "    ax.legend()\n",
                "    \n",
                "    # 3. Gradient visualization (gradient of path gain w.r.t. position)\n",
                "    ax = axes[2]\n",
                "    \n",
                "    # Compute gradient numerically\n",
                "    eps = 0.01\n",
                "    dx = np.zeros_like(sampled_map)\n",
                "    dy = np.zeros_like(sampled_map)\n",
                "    \n",
                "    for i in range(1, sampled_map.shape[0]-1):\n",
                "        for j in range(1, sampled_map.shape[1]-1):\n",
                "            dx[i, j] = (sampled_map[i, j+1] - sampled_map[i, j-1]) / (2 * (grid_x[1] - grid_x[0]))\n",
                "            dy[i, j] = (sampled_map[i+1, j] - sampled_map[i-1, j]) / (2 * (grid_y[1] - grid_y[0]))\n",
                "    \n",
                "    grad_mag = np.sqrt(dx**2 + dy**2)\n",
                "    im = ax.imshow(grad_mag, cmap='viridis', origin='lower', extent=[0, 1, 0, 1])\n",
                "    \n",
                "    # Overlay gradient arrows (subsampled)\n",
                "    step = 5\n",
                "    ax.quiver(xx[::step, ::step], yy[::step, ::step], \n",
                "              dx[::step, ::step], dy[::step, ::step], \n",
                "              color='white', alpha=0.7, scale=50)\n",
                "    \n",
                "    ax.scatter(true_pos[0], true_pos[1], c='lime', s=100, marker='*', \n",
                "               edgecolors='black', zorder=10)\n",
                "    ax.set_title('Gradient Magnitude (for physics loss)', fontsize=12)\n",
                "    plt.colorbar(im, ax=ax, label='|∇f|')\n",
                "    \n",
                "    plt.suptitle('Differentiable Bilinear Resampling', fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_bilinear_sampling(batch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4fb579d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_physics_loss_demo(batch, outputs, sample_idx=0):\n",
                "    \"\"\"Demonstrate physics loss computation.\"\"\"\n",
                "    \n",
                "    # Get the number of radio map channels\n",
                "    num_channels = batch['radio_map'].shape[1]\n",
                "    \n",
                "    # Feature names matching the radio map channels\n",
                "    channel_names = ('path_gain', 'toa', 'aoa', 'snr', 'sinr')[:num_channels]\n",
                "    \n",
                "    # Setup physics loss with feature weights from the project\n",
                "    config = PhysicsLossConfig(\n",
                "        feature_weights={\n",
                "            'path_gain': 1.0,\n",
                "            'toa': 0.5,\n",
                "            'aoa': 0.3,\n",
                "            'snr': 0.8,\n",
                "            'sinr': 0.8,\n",
                "        },\n",
                "        map_extent=(0.0, 0.0, 1.0, 1.0),\n",
                "        loss_type='mse',\n",
                "        normalize_features=False,\n",
                "        channel_names=channel_names,\n",
                "    )\n",
                "    physics_loss_fn = PhysicsLoss(config).to(batch['radio_map'].device)\n",
                "    \n",
                "    # Get predicted positions\n",
                "    pred_pos = outputs['predicted_position']  # [B, 2]\n",
                "    true_pos = batch['position']  # [B, 2]\n",
                "    \n",
                "    # Extract observed features from measurements (simplified)\n",
                "    # In practice, these come from the actual measurements\n",
                "    observed_features = differentiable_lookup(\n",
                "        true_pos, \n",
                "        batch['radio_map'], \n",
                "        (0.0, 0.0, 1.0, 1.0)\n",
                "    )\n",
                "    \n",
                "    # Compute physics loss for predicted positions\n",
                "    physics_loss_pred = physics_loss_fn(pred_pos, observed_features, batch['radio_map'])\n",
                "    \n",
                "    # Compute physics loss for ground truth (should be ~0)\n",
                "    physics_loss_gt = physics_loss_fn(true_pos, observed_features, batch['radio_map'])\n",
                "    \n",
                "    print(\"=\" * 60)\n",
                "    print(\"PHYSICS LOSS COMPUTATION\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"\\nPhysics Loss at Predicted Positions: {physics_loss_pred.item():.6f}\")\n",
                "    print(f\"Physics Loss at Ground Truth:        {physics_loss_gt.item():.6f}\")\n",
                "    print(f\"Difference:                          {(physics_loss_pred - physics_loss_gt).item():.6f}\")\n",
                "    print(\"\\nNote: Ground truth loss should be near 0 (features match exactly)\")\n",
                "    print(\"      The loss difference indicates how much the prediction deviates\")\n",
                "    print(\"      from physics-consistent positions.\")\n",
                "    \n",
                "    # Visualize feature comparison\n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    print(\"FEATURE COMPARISON (Sample 0)\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # Sample features at predicted and true positions\n",
                "    pred_features = differentiable_lookup(pred_pos, batch['radio_map'], (0.0, 0.0, 1.0, 1.0))\n",
                "    true_features = observed_features\n",
                "    \n",
                "    print(f\"\\n{'Feature':15s} | {'Observed':>12s} | {'At Predicted':>12s} | {'Residual':>12s}\")\n",
                "    print(\"-\" * 60)\n",
                "    for i, name in enumerate(channel_names):\n",
                "        obs = true_features[0, i].item()\n",
                "        pred = pred_features[0, i].item()\n",
                "        residual = abs(obs - pred)\n",
                "        print(f\"{name:15s} | {obs:12.4f} | {pred:12.4f} | {residual:12.4f}\")\n",
                "    \n",
                "    return physics_loss_pred, physics_loss_gt\n",
                "\n",
                "physics_loss_pred, physics_loss_gt = compute_physics_loss_demo(batch, outputs)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3810ee7",
            "metadata": {},
            "source": [
                "## 9. Inference-Time Position Refinement (MAP Refinement)\n",
                "\n",
                "**Plots: Refinement Trajectory (2 panels)**\n",
                "\n",
                "At inference time, predictions can be refined via gradient descent:\n",
                "\n",
                "$$E(\\mathbf{y}) = \\mathcal{L}_{\\text{phys}}(\\mathbf{y}) + \\lambda_{\\text{dens}} \\cdot \\text{NLL}(\\mathbf{y} | \\text{network})$$\n",
                "\n",
                "1. **Trajectory on Map** - Shows initial (red) → refined (blue) path with ground truth (green star)\n",
                "2. **Error Comparison** - Bar chart showing error reduction with improvement annotation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "249cb70e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.physics_loss import refine_position, RefineConfig\n",
                "\n",
                "def demonstrate_position_refinement(batch, outputs, sample_idx=0, scene_extent=512.0):\n",
                "    \"\"\"Demonstrate inference-time position refinement using physics loss.\"\"\"\n",
                "    \n",
                "    # Get initial prediction\n",
                "    initial_pos = outputs['predicted_position'].clone()\n",
                "    true_pos = batch['position']\n",
                "    \n",
                "    # Extract observed features (from ground truth for demonstration)\n",
                "    observed_features = differentiable_lookup(\n",
                "        true_pos, \n",
                "        batch['radio_map'], \n",
                "        (0.0, 0.0, 1.0, 1.0)\n",
                "    )\n",
                "    \n",
                "    # Configure refinement\n",
                "    refine_config = RefineConfig(\n",
                "        num_steps=50,\n",
                "        learning_rate=0.01,\n",
                "        min_confidence_threshold=None,  # Refine all samples\n",
                "        density_weight=0.1,\n",
                "        clip_to_extent=True,\n",
                "        map_extent=(0.0, 0.0, 1.0, 1.0),\n",
                "        physics_config=PhysicsLossConfig(\n",
                "            map_extent=(0.0, 0.0, 1.0, 1.0),\n",
                "            loss_type='mse',\n",
                "        ),\n",
                "    )\n",
                "    \n",
                "    # Run refinement\n",
                "    refined_pos, refine_info = refine_position(\n",
                "        initial_xy=initial_pos,\n",
                "        observed_features=observed_features,\n",
                "        radio_maps=batch['radio_map'],\n",
                "        config=refine_config,\n",
                "    )\n",
                "    \n",
                "    # Compute errors\n",
                "    initial_errors = torch.norm((initial_pos - true_pos) * scene_extent, dim=1).cpu().numpy()\n",
                "    refined_errors = torch.norm((refined_pos - true_pos) * scene_extent, dim=1).cpu().numpy()\n",
                "    \n",
                "    print(\"=\" * 60)\n",
                "    print(\"POSITION REFINEMENT RESULTS\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"\\nInitial Physics Loss:  {refine_info['loss_initial']:.6f}\")\n",
                "    print(f\"Final Physics Loss:    {refine_info['loss_final']:.6f}\")\n",
                "    print(f\"Samples Refined:       {refine_info['num_refined']}\")\n",
                "    print(f\"\\nError Comparison (meters):\")\n",
                "    print(f\"  Initial Mean Error:  {initial_errors.mean():.2f} m\")\n",
                "    print(f\"  Refined Mean Error:  {refined_errors.mean():.2f} m\")\n",
                "    print(f\"  Improvement:         {initial_errors.mean() - refined_errors.mean():.2f} m\")\n",
                "    \n",
                "    return initial_pos, refined_pos, initial_errors, refined_errors\n",
                "\n",
                "initial_pos, refined_pos, initial_errors, refined_errors = demonstrate_position_refinement(batch, outputs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "810da386",
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_refinement(batch, initial_pos, refined_pos, sample_idx=0, scene_extent=512.0):\n",
                "    \"\"\"Visualize the position refinement trajectory.\"\"\"\n",
                "    true_pos = batch['position'][sample_idx].cpu().numpy()\n",
                "    init_pos = initial_pos[sample_idx].cpu().numpy()\n",
                "    ref_pos = refined_pos[sample_idx].cpu().numpy()\n",
                "    \n",
                "    radio_map = batch['radio_map'][sample_idx, 0].cpu().numpy()  # Path Gain\n",
                "    h, w = radio_map.shape\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "    \n",
                "    # 1. Visualization on radio map\n",
                "    ax = axes[0]\n",
                "    im = ax.imshow(radio_map, cmap='inferno', origin='lower', extent=[0, 1, 0, 1])\n",
                "    \n",
                "    # Draw arrow from initial to refined\n",
                "    ax.annotate('', xy=(ref_pos[0], ref_pos[1]), xytext=(init_pos[0], init_pos[1]),\n",
                "                arrowprops=dict(arrowstyle='->', color='cyan', lw=2))\n",
                "    \n",
                "    ax.scatter(true_pos[0], true_pos[1], c='lime', s=150, marker='*', \n",
                "               edgecolors='black', label='Ground Truth', zorder=10)\n",
                "    ax.scatter(init_pos[0], init_pos[1], c='red', s=80, marker='o', \n",
                "               edgecolors='black', label='Initial Pred', zorder=9)\n",
                "    ax.scatter(ref_pos[0], ref_pos[1], c='blue', s=80, marker='s', \n",
                "               edgecolors='black', label='Refined Pred', zorder=9)\n",
                "    \n",
                "    ax.set_xlim([0, 1])\n",
                "    ax.set_ylim([0, 1])\n",
                "    ax.set_title(f'Position Refinement (Sample {sample_idx})', fontsize=12)\n",
                "    ax.set_xlabel('X (normalized)')\n",
                "    ax.set_ylabel('Y (normalized)')\n",
                "    plt.colorbar(im, ax=ax, label='Path Gain')\n",
                "    ax.legend(loc='upper right')\n",
                "    \n",
                "    # 2. Error comparison bar chart\n",
                "    ax = axes[1]\n",
                "    \n",
                "    init_error = np.linalg.norm(init_pos - true_pos) * scene_extent\n",
                "    ref_error = np.linalg.norm(ref_pos - true_pos) * scene_extent\n",
                "    \n",
                "    bars = ax.bar(['Initial', 'Refined'], [init_error, ref_error], \n",
                "                  color=['coral', 'steelblue'], edgecolor='black')\n",
                "    \n",
                "    # Add improvement annotation\n",
                "    improvement = init_error - ref_error\n",
                "    improvement_pct = (improvement / init_error) * 100 if init_error > 0 else 0\n",
                "    \n",
                "    ax.annotate(f'Δ = {improvement:.1f}m ({improvement_pct:.1f}%)',\n",
                "                xy=(1, ref_error), xytext=(1.3, (init_error + ref_error) / 2),\n",
                "                fontsize=11, ha='left',\n",
                "                arrowprops=dict(arrowstyle='->', color='green', lw=1.5))\n",
                "    \n",
                "    ax.set_ylabel('Localization Error (m)', fontsize=12)\n",
                "    ax.set_title('Error Before/After Refinement', fontsize=12)\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    \n",
                "    # Annotate bars\n",
                "    for bar, val in zip(bars, [init_error, ref_error]):\n",
                "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
                "                f'{val:.1f}m', ha='center', va='bottom', fontsize=11)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "visualize_refinement(batch, initial_pos, refined_pos)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "853bbc42",
            "metadata": {},
            "source": [
                "## 10. Position Refinement with Physics Loss\n",
                "\n",
                "**Demonstration: Inference-Time Optimization**\n",
                "\n",
                "After initial prediction, we can refine positions using gradient descent on the physics loss:\n",
                "\n",
                "$$\\hat{\\mathbf{x}}_{t+1} = \\hat{\\mathbf{x}}_t - \\eta \\nabla_{\\mathbf{x}} \\mathcal{L}_{\\text{phys}}(\\hat{\\mathbf{x}}_t)$$\n",
                "\n",
                "This optimization uses differentiable bilinear interpolation to:\n",
                "1. Sample radio map features at predicted position\n",
                "2. Compare with observed measurements\n",
                "3. Update position to minimize discrepancy\n",
                "\n",
                "Visualizations show the refinement trajectory and error improvement."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1ae4e4f1",
            "metadata": {},
            "source": [
                "## 11. Summary Dashboard\n",
                "\n",
                "**Plot: Multi-Panel Summary (5 components)**\n",
                "\n",
                "Comprehensive overview combining all key results:\n",
                "\n",
                "1. **Metrics Table** - Median, RMSE, 67th/90th percentiles\n",
                "2. **Loss Pie Chart** - Coarse vs Fine loss contribution breakdown\n",
                "3. **Per-Sample Bars** - Initial vs Refined error for each sample\n",
                "4. **CDF Comparison** - Before/After refinement curves\n",
                "5. **Architecture Diagram** - Text summary of model components\n",
                "\n",
                "### Total Training Loss\n",
                "\n",
                "$$\\mathcal{L}_{\\text{total}} = \\underbrace{\\lambda_{\\text{coarse}} \\mathcal{L}_{\\text{coarse}}}_{\\text{Cross-Entropy}} + \\underbrace{\\lambda_{\\text{fine}} \\mathcal{L}_{\\text{fine}}}_{\\text{Mixture NLL}} + \\underbrace{\\lambda_{\\text{phys}} \\mathcal{L}_{\\text{phys}}}_{\\text{Physics Consistency}}$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee1d08d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_summary_visualization(metrics, losses, initial_errors, refined_errors, scene_extent=512.0):\n",
                "    \"\"\"Create a comprehensive summary visualization.\"\"\"\n",
                "    \n",
                "    fig = plt.figure(figsize=(16, 10))\n",
                "    \n",
                "    # Create grid layout\n",
                "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
                "    \n",
                "    # 1. Metrics table\n",
                "    ax = fig.add_subplot(gs[0, 0])\n",
                "    ax.axis('off')\n",
                "    \n",
                "    table_data = [\n",
                "        ['Metric', 'Value'],\n",
                "        ['Median Error', f\"{metrics['Median Error (m)']:.2f} m\"],\n",
                "        ['RMSE', f\"{metrics['RMSE (m)']:.2f} m\"],\n",
                "        ['67th Percentile', f\"{metrics['67th Percentile (m)']:.2f} m\"],\n",
                "        ['90th Percentile', f\"{metrics['90th Percentile (m)']:.2f} m\"],\n",
                "    ]\n",
                "    \n",
                "    table = ax.table(cellText=table_data, loc='center', cellLoc='center',\n",
                "                     colWidths=[0.5, 0.5])\n",
                "    table.auto_set_font_size(False)\n",
                "    table.set_fontsize(11)\n",
                "    table.scale(1.2, 1.5)\n",
                "    \n",
                "    # Color header row\n",
                "    for i in range(2):\n",
                "        table[(0, i)].set_facecolor('#4472C4')\n",
                "        table[(0, i)].set_text_props(color='white', weight='bold')\n",
                "    \n",
                "    ax.set_title('Evaluation Metrics', fontsize=14, pad=20)\n",
                "    \n",
                "    # 2. Loss breakdown pie chart\n",
                "    ax = fig.add_subplot(gs[0, 1])\n",
                "    loss_values = [losses['coarse_loss'].item(), losses['fine_loss'].item()]\n",
                "    loss_labels = ['Coarse\\n(CE)', 'Fine\\n(NLL)']\n",
                "    colors = ['#FF6B6B', '#4ECDC4']\n",
                "    \n",
                "    wedges, texts, autotexts = ax.pie(loss_values, labels=loss_labels, colors=colors,\n",
                "                                       autopct='%1.1f%%', startangle=90,\n",
                "                                       explode=(0.05, 0.05))\n",
                "    ax.set_title('Loss Breakdown', fontsize=14)\n",
                "    \n",
                "    # 3. Before/After Refinement comparison\n",
                "    ax = fig.add_subplot(gs[0, 2])\n",
                "    \n",
                "    x = np.arange(len(initial_errors))\n",
                "    width = 0.35\n",
                "    \n",
                "    ax.bar(x - width/2, initial_errors, width, label='Initial', color='coral', alpha=0.8)\n",
                "    ax.bar(x + width/2, refined_errors, width, label='Refined', color='steelblue', alpha=0.8)\n",
                "    \n",
                "    ax.set_xlabel('Sample Index')\n",
                "    ax.set_ylabel('Error (m)')\n",
                "    ax.set_title('Per-Sample Refinement Improvement', fontsize=14)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3, axis='y')\n",
                "    \n",
                "    # 4. CDF comparison\n",
                "    ax = fig.add_subplot(gs[1, :2])\n",
                "    \n",
                "    sorted_init = np.sort(initial_errors)\n",
                "    sorted_ref = np.sort(refined_errors)\n",
                "    cdf = np.arange(1, len(sorted_init) + 1) / len(sorted_init) * 100\n",
                "    \n",
                "    ax.plot(sorted_init, cdf, 'o-', linewidth=2, label='Initial', color='coral', markersize=8)\n",
                "    ax.plot(sorted_ref, cdf, 's-', linewidth=2, label='After Refinement', color='steelblue', markersize=8)\n",
                "    \n",
                "    ax.axhline(67, color='gray', linestyle='--', alpha=0.5)\n",
                "    ax.axhline(90, color='gray', linestyle='--', alpha=0.5)\n",
                "    ax.text(ax.get_xlim()[1] * 0.98, 67, '67%', ha='right', va='bottom', fontsize=10)\n",
                "    ax.text(ax.get_xlim()[1] * 0.98, 90, '90%', ha='right', va='bottom', fontsize=10)\n",
                "    \n",
                "    ax.set_xlabel('Localization Error (m)', fontsize=12)\n",
                "    ax.set_ylabel('CDF (%)', fontsize=12)\n",
                "    ax.set_title('Error CDF: Before vs After Physics Refinement', fontsize=14)\n",
                "    ax.legend(fontsize=11)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    ax.set_ylim([0, 105])\n",
                "    \n",
                "    # 5. Model architecture summary\n",
                "    ax = fig.add_subplot(gs[1, 2])\n",
                "    ax.axis('off')\n",
                "    \n",
                "    arch_text = \"\"\"\n",
                "    Model Architecture\n",
                "    ══════════════════\n",
                "    \n",
                "    1. Radio Encoder\n",
                "       └─ Set Transformer\n",
                "    \n",
                "    2. Map Encoder\n",
                "       └─ ViT (E2-Equivariant)\n",
                "    \n",
                "    3. Cross-Attention Fusion\n",
                "       └─ Multi-head attention\n",
                "    \n",
                "    4. Coarse Head\n",
                "       └─ Grid cell classifier\n",
                "    \n",
                "    5. Fine Head\n",
                "       └─ GMM (μ, σ) predictor\n",
                "    \n",
                "    6. Physics Regularization\n",
                "       └─ Differentiable lookup\n",
                "    \"\"\"\n",
                "    \n",
                "    ax.text(0.1, 0.95, arch_text, transform=ax.transAxes, fontsize=10,\n",
                "            verticalalignment='top', fontfamily='monospace',\n",
                "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
                "    \n",
                "    plt.suptitle('UE Localization Pipeline - Summary', fontsize=16, y=1.02)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Create final summary\n",
                "create_summary_visualization(metrics, losses, initial_errors, refined_errors)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
