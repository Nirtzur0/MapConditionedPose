{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UE Localization Visualization\n\nA compact notebook for the core plots and sanity checks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "423fe258",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-28T11:53:59.365421Z",
          "iopub.status.busy": "2026-01-28T11:53:59.365238Z",
          "iopub.status.idle": "2026-01-28T11:54:05.986056Z",
          "shell.execute_reply": "2026-01-28T11:54:05.985272Z"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import importlib\n",
        "\n",
        "# Ensure matplotlib renders inline in notebooks\n",
        "try:\n",
        "    from IPython import get_ipython\n",
        "    ip = get_ipython()\n",
        "    if ip is not None:\n",
        "        ip.run_line_magic('matplotlib', 'inline')\n",
        "except Exception:\n",
        "    pass\n",
        "try:\n",
        "    from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "    set_matplotlib_formats('png')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Notebook verbosity control\n",
        "VERBOSE = False\n",
        "\n",
        "# Get the absolute path to project root\n",
        "project_root = Path(\"/home/ubuntu/projects/MapConditionedPose\")\n",
        "\n",
        "if VERBOSE:\n",
        "    print(f\"Project root: {project_root}\")\n",
        "\n",
        "# Change to project root\n",
        "os.chdir(project_root)\n",
        "\n",
        "# Add src to path\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Force deep reload of all src modules by removing them from cache first\n",
        "to_remove = [key for key in sys.modules.keys() if key.startswith('src.')]\n",
        "for key in to_remove:\n",
        "    del sys.modules[key]\n",
        "\n",
        "from src.training import UELocalizationLightning\n",
        "# Note: collate_fn is now None (uses PyTorch default) for LMDB dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Resolve checkpoint + dataset paths\n",
        "from src.notebook_plot_helpers import (\n",
        "    resolve_checkpoint_and_config,\n",
        "    resolve_lmdb_paths,\n",
        "    load_model_and_batch,\n",
        "    visualize_feature_histograms,\n",
        "    visualize_maps,\n",
        "    visualize_lidar_height,\n",
        "    plot_ue_tx_scatter,\n",
        "    plot_ue_trajectories,\n",
        "    list_available_scenes,\n",
        "    visualize_sionna_3d_scene,\n",
        "    render_prediction,\n",
        "    compute_evaluation_metrics,\n",
        "    plot_error_analysis,\n",
        "    compute_loss_breakdown,\n",
        "    visualize_coarse_heatmap,\n",
        "    visualize_fine_refinement,\n",
        "    plot_error_on_building_map,\n",
        ")\n",
        "\n",
        "CHECKPOINT_DIR = 'outputs'\n",
        "CHECKPOINT_PATH = ''\n",
        "CHECKPOINT_EPOCH = None\n",
        "ckpt_notes = []\n",
        "\n",
        "# For debugging without checkpoint, use direct dataset path\n",
        "USE_DIRECT_DATASET = True\n",
        "if USE_DIRECT_DATASET:\n",
        "    DATASET_PATH = '/home/ubuntu/projects/MapConditionedPose/outputs/experiment_2tx_2vars_1000ue/data/dataset_20260128_144040_test.lmdb'\n",
        "    BASE_CONFIG_PATH = '/home/ubuntu/projects/MapConditionedPose/outputs/experiment_2tx_2vars_1000ue/config.yaml'\n",
        "else:\n",
        "    CHECKPOINT_PATH, BASE_CONFIG_PATH, ckpt_notes = resolve_checkpoint_and_config(\n",
        "        checkpoint_dir=CHECKPOINT_DIR,\n",
        "        checkpoint_path=CHECKPOINT_PATH,\n",
        "        checkpoint_epoch=CHECKPOINT_EPOCH,\n",
        "    )\n",
        "    DATASET_PATH, TRAIN_PATH, VAL_PATH, TEST_PATH = resolve_lmdb_paths()\n",
        "\n",
        "if VERBOSE:\n",
        "    print(f'Checkpoint: {CHECKPOINT_PATH}')\n",
        "    print(f'Config: {BASE_CONFIG_PATH}')\n",
        "    print(f'Dataset: {DATASET_PATH}')\n",
        "    if ckpt_notes:\n",
        "        print('Notes:')\n",
        "        for note in ckpt_notes:\n",
        "            print(f'- {note}')\n",
        "elif ckpt_notes:\n",
        "    print(' | '.join(ckpt_notes))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load model and build a batch\n",
        "TARGET_BATCH_IDX = 1\n",
        "model, batch, val_loader = load_model_and_batch(\n",
        "    CHECKPOINT_PATH,\n",
        "    BASE_CONFIG_PATH,\n",
        "    TRAIN_PATH if 'TRAIN_PATH' in globals() else None,\n",
        "    VAL_PATH if 'VAL_PATH' in globals() else None,\n",
        "    TEST_PATH if 'TEST_PATH' in globals() else None,\n",
        "    target_batch_idx=TARGET_BATCH_IDX,\n",
        "    verbose=VERBOSE,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SAMPLE_IDX = 0\n",
        "\n",
        "if 'batch' not in globals():\n",
        "    raise RuntimeError('batch not defined; run the setup cell above')\n",
        "\n",
        "SCENE_ID = None\n",
        "SCENE_IDX = None\n",
        "GLOBAL_SAMPLE_IDX = None\n",
        "if 'scene_idx' in batch:\n",
        "    try:\n",
        "        SCENE_IDX = int(batch['scene_idx'][SAMPLE_IDX].item())\n",
        "    except Exception:\n",
        "        SCENE_IDX = None\n",
        "if SCENE_IDX is not None and hasattr(val_loader, 'dataset'):\n",
        "    meta = getattr(val_loader.dataset, '_metadata', None)\n",
        "    if meta:\n",
        "        scene_ids = meta.get('scene_ids')\n",
        "        if scene_ids and 0 <= SCENE_IDX < len(scene_ids):\n",
        "            SCENE_ID = scene_ids[SCENE_IDX]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data sanity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature distributions (RadioEncoder inputs only)\n",
        "visualize_feature_histograms(batch, max_dims=12)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Map context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Map layers\n",
        "visualize_maps(batch, sample_idx=SAMPLE_IDX)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: LiDAR height channel\n",
        "visualize_lidar_height(batch, sample_idx=SAMPLE_IDX)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# UE/TX positions\n",
        "plot_ue_tx_scatter(val_loader.dataset, coord_mode=\"auto\", ue_size=25, ue_alpha=0.6, tx_size=120, scene_id_filter=SCENE_ID)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# UE trajectories over map\n",
        "plot_ue_trajectories(\n",
        "    val_loader.dataset,\n",
        "    num_trajectories=12,\n",
        "    split=val_loader.dataset.split if hasattr(val_loader, \"dataset\") else \"all\",\n",
        "    scene_id_filter=SCENE_ID,\n",
        "    coord_mode=\"auto\",\n",
        "    show_map=True,\n",
        "    save_path=\"docs/paper/figures/ue_trajectories.png\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 3D Scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3D Sionna scene render with radio overlay\n",
        "available = list_available_scenes()\n",
        "if VERBOSE:\n",
        "    print(f\"Available scenes: {list(available.keys())}\")\n",
        "\n",
        "sionna_radio_map = visualize_sionna_3d_scene(\n",
        "    batch,\n",
        "    sample_idx=SAMPLE_IDX,\n",
        "    scene_name=SCENE_ID,\n",
        "    verbose=VERBOSE,\n",
        "    use_sionna=True,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Model predictions (top-K overlay)\n",
        "outputs = render_prediction(model, batch, sample_idx=SAMPLE_IDX, verbose=VERBOSE)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Coarse heatmap + loss breakdown\n",
        "losses, outputs = compute_loss_breakdown(model, batch)\n",
        "visualize_coarse_heatmap(outputs, batch, sample_idx=SAMPLE_IDX)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fine refinement visualization\n",
        "visualize_fine_refinement(outputs, batch, sample_idx=SAMPLE_IDX)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Error metrics + distributions\n",
        "metrics, errors_m, pred_pos, true_pos, scene_extent = compute_evaluation_metrics(model, batch)\n",
        "plot_error_analysis(errors_m, \"Batch Error Analysis\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Error overlay on building footprint\n",
        "plot_error_on_building_map(\n",
        "    model,\n",
        "    val_loader,\n",
        "    max_batches=10,\n",
        "    save_path=\"docs/paper/figures/error_on_building_map.png\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}